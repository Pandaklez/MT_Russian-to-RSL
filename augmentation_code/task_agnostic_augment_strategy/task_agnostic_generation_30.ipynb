{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d586988",
   "metadata": {
    "cellId": "ntaun1g9j6na6cuc1rvmmg"
   },
   "source": [
    "## Task agnostic data augmentation\n",
    "\n",
    "* take random russian texts\n",
    "* lemmatize\n",
    "* make random word order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3973252",
   "metadata": {
    "cellId": "x26q1pibqzkkxmn3dnhcuo"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "with open('lenta.txt', 'r', encoding='utf-8') as file:\n",
    "    lenta_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4b5c958",
   "metadata": {
    "cellId": "mbogru0puyhy0xzrbe0pmm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Бои у Сопоцкина и Друскеник за'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "lenta_data[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29632e26",
   "metadata": {
    "cellId": "8src0jnt7u3ukzgi7sbmsa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11536552"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "len(lenta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eac81321",
   "metadata": {
    "cellId": "au79xssrqhssaawqbq13bg"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from razdel import sentenize\n",
    "from pymystem3 import Mystem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f595fda",
   "metadata": {
    "cellId": "bocnxjnkfp1qws7mprsgih"
   },
   "source": [
    "- Split into separate sentences\n",
    "- tokenize and lemmatize this sentences and keep this in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0bc8bdc",
   "metadata": {
    "cellId": "vtfe3xhvwtgu0z38ow6igh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75659/75659 [01:14<00:00, 1019.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['неприятель',\n",
      " 'приближаться',\n",
      " 'артиллерийский',\n",
      " 'крепость',\n",
      " 'осовец',\n",
      " 'начинать',\n",
      " 'север',\n",
      " 'к',\n",
      " 'борьба',\n",
      " 'с',\n",
      " 'с']\n",
      "['неприятель', 'приближаться', 'с', 'север', 'к', 'осовец', 'начинать', 'артиллерийский', 'борьба', 'с', 'крепость']\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "russian_sents = []\n",
    "lemma_sents = []\n",
    "fake_rsl_sents = []\n",
    "\n",
    "mystem = Mystem(entire_input=False)\n",
    "\n",
    "for sentence in tqdm(list(sentenize(lenta_data))):  # take all data\n",
    "    russian_sents.append(sentence.text)\n",
    "    \n",
    "    lemma_sent = mystem.lemmatize(sentence.text)\n",
    "    lemma_sents.append(lemma_sent)\n",
    "    fake_rsl_sents.append(random.sample(lemma_sent, len(lemma_sent)))\n",
    "\n",
    "pprint(fake_rsl_sents[1])\n",
    "print(lemma_sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b95d14d",
   "metadata": {
    "cellId": "ds4jllot8lrv8mo8eipet"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "generated_data = pd.DataFrame()\n",
    "generated_data['rsl'] = fake_rsl_sents\n",
    "generated_data['rus'] = russian_sents\n",
    "generated_data['lemmatized'] = lemma_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfccb28a",
   "metadata": {
    "cellId": "87prlo8yiibhumba228q7t"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rsl</th>\n",
       "      <th>rus</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[бой, заканчиваться, друскеник, сопоцкин, у, о...</td>\n",
       "      <td>Бои у Сопоцкина и Друскеник закончились отступ...</td>\n",
       "      <td>[бой, у, сопоцкин, и, друскеник, заканчиваться...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[неприятель, приближаться, артиллерийский, кре...</td>\n",
       "      <td>Неприятель, приблизившись с севера к Осовцу на...</td>\n",
       "      <td>[неприятель, приближаться, с, север, к, осовец...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[принимать, участие, тяжелый, в, калибр, бой, ...</td>\n",
       "      <td>В артиллерийском бою принимают участие тяжелые...</td>\n",
       "      <td>[в, артиллерийский, бой, принимать, участие, т...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[утро, достигать, значительный, огонь, напряже...</td>\n",
       "      <td>С раннего утра 14 сентября огонь достиг значит...</td>\n",
       "      <td>[с, ранний, утро, сентябрь, огонь, достигать, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[пехота, крепость, пробиваться, германский, бл...</td>\n",
       "      <td>Попытка германской пехоты пробиться ближе к кр...</td>\n",
       "      <td>[попытка, германский, пехота, пробиваться, бли...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 rsl  \\\n",
       "0  [бой, заканчиваться, друскеник, сопоцкин, у, о...   \n",
       "1  [неприятель, приближаться, артиллерийский, кре...   \n",
       "2  [принимать, участие, тяжелый, в, калибр, бой, ...   \n",
       "3  [утро, достигать, значительный, огонь, напряже...   \n",
       "4  [пехота, крепость, пробиваться, германский, бл...   \n",
       "\n",
       "                                                 rus  \\\n",
       "0  Бои у Сопоцкина и Друскеник закончились отступ...   \n",
       "1  Неприятель, приблизившись с севера к Осовцу на...   \n",
       "2  В артиллерийском бою принимают участие тяжелые...   \n",
       "3  С раннего утра 14 сентября огонь достиг значит...   \n",
       "4  Попытка германской пехоты пробиться ближе к кр...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [бой, у, сопоцкин, и, друскеник, заканчиваться...  \n",
       "1  [неприятель, приближаться, с, север, к, осовец...  \n",
       "2  [в, артиллерийский, бой, принимать, участие, т...  \n",
       "3  [с, ранний, утро, сентябрь, огонь, достигать, ...  \n",
       "4  [попытка, германский, пехота, пробиваться, бли...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "generated_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c46e0dfa",
   "metadata": {
    "cellId": "yv4wab5a6dxykknk34coh"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import os, sys\n",
    "sys.path.append('../')\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from argparse import Namespace\n",
    "from pyeaf.text import VocabularyVectorizer, TextStemmer, RSLStemmer, GramBinarizer\n",
    "\n",
    "\n",
    "st = TextStemmer()\n",
    "\n",
    "stem_sentences_rus, gram_sentences_rus = st.stem(generated_data['rus'], gram=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a732cc6b",
   "metadata": {
    "cellId": "fyu8jvh3k3dcegpqt77e1o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['бой',\n",
       "  'у',\n",
       "  'сопоцкина',\n",
       "  'и',\n",
       "  'друскеник',\n",
       "  'заканчиваться',\n",
       "  'отступление',\n",
       "  'германец'],\n",
       " ['неприятель',\n",
       "  'приближаться',\n",
       "  'с',\n",
       "  'север',\n",
       "  'к',\n",
       "  'осовец',\n",
       "  'начинать',\n",
       "  'артиллерийский',\n",
       "  'борьба',\n",
       "  'с',\n",
       "  'крепость']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "stem_sentences_rus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba5bda93",
   "metadata": {
    "cellId": "j8hde3hxc4n9ck2wckx3"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import json\n",
    "\n",
    "test_data = pd.read_csv('test_data.csv', encoding='utf-8')\n",
    "\n",
    "test_data['test_stem_rus'] = test_data['test_stem_rus'].apply(lambda sent: sent.strip('[]\\'').split('\\', \\''))\n",
    "test_data['test_rsl'] = test_data['test_rsl'].apply(lambda sent: sent.strip('[]\\'').split('\\', \\''))\n",
    "test_data['test_gram_rus'] = test_data['test_gram_rus'].apply(lambda sent: json.loads(sent.replace('\\'', '\\\"')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e07ccf1",
   "metadata": {
    "cellId": "hn2it4o2ap28kdiut1vnz"
   },
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2bce0e1",
   "metadata": {
    "cellId": "j4wlq7uxh9w5unludh5u"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "voc_rus = VocabularyVectorizer(phrase_border=True)\n",
    "bin_gram = GramBinarizer(phrase_border=True)\n",
    "voc_rsl = VocabularyVectorizer(phrase_border=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a016725d",
   "metadata": {
    "cellId": "uofrsop2rkk04xa1qjak6t8"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "voc_rus = voc_rus.fit(stem_sentences_rus)\n",
    "bin_gram = bin_gram.fit(gram_sentences_rus)\n",
    "voc_rsl = voc_rsl.fit(list(generated_data['rsl']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5d83744",
   "metadata": {
    "cellId": "n9drhzk3g39uiq68193u5"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Save\\load vocabs\n",
    "import pickle\n",
    "\n",
    "def save_vocab(vocab, path):\n",
    "    output = open(path, 'wb')\n",
    "    pickle.dump(vocab, output)\n",
    "    output.close()\n",
    "    \n",
    "def load_vocab(path):\n",
    "    output = open(path, 'rb')\n",
    "    vocab = pickle.load(output)\n",
    "    output.close()\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7564ef74",
   "metadata": {
    "cellId": "c6r3txap9yd7a5uznqffj"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "save_vocab(voc_rus, 'voc_rus4.pkl')\n",
    "save_vocab(bin_gram, 'bin_gram4.pkl')\n",
    "save_vocab(voc_rsl, 'voc_rsl4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7675c17b",
   "metadata": {
    "cellId": "f9gfr5onoei7m5fzz7yu5h"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Load vocabs\n",
    "#voc_rus = load_vocab('voc_rus2.pkl')\n",
    "#bin_gram = load_vocab('bin_gram2.pkl')\n",
    "#voc_rsl = load_vocab('voc_rsl2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64c2caff",
   "metadata": {
    "cellId": "24z7t1t3ctg33b1rtc50qy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['бой']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "voc_rus.index_to_text([[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acfb7398",
   "metadata": {
    "cellId": "lzh4e8xkstpl2mwar6i2mp"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "vec_sentences_rus_train = voc_rus.text_to_index(stem_sentences_rus)\n",
    "vec_gram_train = bin_gram.transform(gram_sentences_rus)\n",
    "vec_sentences_rsl_train = voc_rsl.text_to_index(list(generated_data['rsl']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b78e74a0",
   "metadata": {
    "cellId": "stxps8dbvrpw07kqcb0qw"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "words = [w for s in list(generated_data['rsl']) for w in s]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f7216c",
   "metadata": {
    "cellId": "qf285dv22i81eh1i4th14"
   },
   "source": [
    "### Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ba69387",
   "metadata": {
    "cellId": "0l59izjf96jcqtlkyny4k"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from model.model import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34458d4f",
   "metadata": {
    "cellId": "bgo6wx56pu99piqwkg30vq"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "    \n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "         \n",
    "        # If loss worsened\n",
    "        if loss_t >= loss_tm1:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def normalize_sizes(y_pred, y_true):\n",
    "    \"\"\"Normalize tensor sizes\n",
    "    \n",
    "    Args:\n",
    "        y_pred (torch.Tensor): the output of the model\n",
    "            If a 3-dimensional tensor, reshapes to a matrix\n",
    "        y_true (torch.Tensor): the target predictions\n",
    "            If a matrix, reshapes to be a vector\n",
    "    \"\"\"\n",
    "    if len(y_pred.size()) == 3:\n",
    "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n",
    "    if len(y_true.size()) == 2:\n",
    "        y_true = y_true.contiguous().view(-1)\n",
    "    return y_pred, y_true\n",
    "\n",
    "def compute_accuracy(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    \n",
    "    correct_indices = torch.eq(y_pred_indices, y_true).float()\n",
    "    valid_indices = torch.ne(y_true, mask_index).float()\n",
    "    \n",
    "    n_correct = (correct_indices * valid_indices).sum().item()\n",
    "    n_valid = valid_indices.sum().item()\n",
    "\n",
    "    return n_correct / n_valid * 100\n",
    "\n",
    "def sequence_loss(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1e3dd2e",
   "metadata": {
    "cellId": "wyyknzwqvirqij6woh96"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import random \n",
    "\n",
    "def batch_generator(rus_data, rsl_data, batch_size=32):\n",
    "    rus_data = np.array(rus_data)\n",
    "    rsl_data = np.array(rsl_data)\n",
    "    \n",
    "    data_length = len(rus_data)\n",
    "    tail_length = batch_size - data_length % batch_size\n",
    "    index = list(range(data_length))\n",
    "    random.shuffle(index)\n",
    "    \n",
    "    index = np.array(index + random.choices(index, k=tail_length))\n",
    "    num_batches = len(index) // batch_size\n",
    "    index = index.reshape((num_batches, batch_size))\n",
    "    \n",
    "    for batch_ind, inds in enumerate(tqdm(index)):\n",
    "        yield batch_ind, torch.tensor(rus_data[inds]), torch.tensor(rsl_data[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d510895",
   "metadata": {
    "cellId": "eb7xb0k184hlgjoiojihs"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from argparse import Namespace\n",
    "from model.model import device\n",
    "\n",
    "args = Namespace(\n",
    "    seed = 1337,\n",
    "    learning_rate = 5e-4, \n",
    "    batch_size = 64,  # 64\n",
    "    num_epochs = 30,  # 30\n",
    "    rus_emb_size = 16,  # 16\n",
    "    rsl_emb_size = 16,  # 16\n",
    "    rnn_size = 64,  # 64\n",
    "    early_stopping_criteria = 5,\n",
    "    mask_index = voc_rsl.mask_ind,\n",
    "    max_norm = 2.0,\n",
    "    norm_type = 2\n",
    ")\n",
    "\n",
    "set_seed_everywhere(args.seed, torch.cuda.is_available())\n",
    "\n",
    "model_zero = Translator(voc_rus.word_count, args.rus_emb_size, voc_rsl.word_count, args.rsl_emb_size, args.rnn_size, voc_rsl.bos_ind)\n",
    "\n",
    "optimizer = optim.Adam(model_zero.parameters(), lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "120bf572",
   "metadata": {
    "cellId": "ttsbturrmr1qj2y1prgtw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b34a558",
   "metadata": {
    "cellId": "ugghtenbblpnj7iux87fo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Translator(\n",
       "  (encoder): TranslatorEncoder(\n",
       "    (rus_embeddings): Embedding(50350, 16, max_norm=1.0)\n",
       "    (rus_birnn): GRU(16, 64, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): TranslatorDecoder(\n",
       "    (rsl_embedding): Embedding(50757, 16, max_norm=1.0)\n",
       "    (gru_cell): GRUCell(144, 128)\n",
       "    (linear_map): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (classifier): Linear(in_features=256, out_features=50757, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "model_zero.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "332130bb",
   "metadata": {
    "cellId": "8at5x2sqw6u96sjeod74m"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [09:43<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Loss:  5.989664720461114 \tacc:  55.86264656616415 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [09:44<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Loss:  2.8882254588835736 \tacc:  81.5068493150685 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [09:43<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2 Loss:  1.7003645707970434 \tacc:  82.72921108742004 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [09:43<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3 Loss:  1.2858160284748557 \tacc:  94.59053343350864 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [09:42<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4 Loss:  1.0655821849255886 \tacc:  86.29518072289156 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [09:44<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5 Loss:  0.9350797632742213 \tacc:  92.58987527512839 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [09:42<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6 Loss:  0.8421056348695054 \tacc:  93.93258426966293 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [09:43<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7 Loss:  0.7732615658189914 \tacc:  92.62711864406779 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [09:44<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8 Loss:  0.7029077553789386 \tacc:  90.04707464694015 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [09:45<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9 Loss:  0.680064434747725 \tacc:  96.79888656924147 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [09:44<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10 Loss:  0.5969116804036463 \tacc:  93.61856417693981 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [09:45<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11 Loss:  0.5850044311113205 \tacc:  90.73668854850474 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [09:43<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12 Loss:  0.5316171836759815 \tacc:  99.57924263674614 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [09:42<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  13 Loss:  0.5124693227426438 \tacc:  99.16142557651992 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [09:43<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  14 Loss:  0.5237196948558771 \tacc:  98.93148962916405 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [09:46<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  15 Loss:  0.6017869923984914 \tacc:  92.32522796352583 \tsample_prob:  0.06666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [09:58<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16 Loss:  1.153186984530263 \tacc:  87.1111111111111 \tsample_prob:  0.13333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [10:08<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  17 Loss:  1.6358763048408018 \tacc:  77.86946736684172 \tsample_prob:  0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [10:18<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  18 Loss:  2.182811187317285 \tacc:  71.83641975308642 \tsample_prob:  0.26666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [10:29<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19 Loss:  2.5814182330064614 \tacc:  68.82591093117408 \tsample_prob:  0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [10:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  20 Loss:  3.0426389950871524 \tacc:  76.70850767085076 \tsample_prob:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [10:51<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  21 Loss:  3.4505207538604754 \tacc:  65.21136521136522 \tsample_prob:  0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [11:02<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  22 Loss:  3.8756305834850027 \tacc:  37.23978411719352 \tsample_prob:  0.5333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [11:12<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  23 Loss:  4.251237797616202 \tacc:  44.868735083532215 \tsample_prob:  0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [11:21<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  24 Loss:  4.631076355053021 \tacc:  41.356184798807746 \tsample_prob:  0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [11:32<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  25 Loss:  4.979520787249559 \tacc:  31.978931527464262 \tsample_prob:  0.7333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [11:42<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  26 Loss:  5.2878783111943095 \tacc:  38.8927820602663 \tsample_prob:  0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [11:53<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  27 Loss:  5.575650962046015 \tacc:  18.550106609808104 \tsample_prob:  0.8666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [12:02<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  28 Loss:  5.837788695112089 \tacc:  14.50381679389313 \tsample_prob:  0.9333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1183/1183 [12:13<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  29 Loss:  5.921336669389817 \tacc:  15.438324282389448 \tsample_prob:  1.0\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# train\n",
    "\n",
    "for epoch_index in range(args.num_epochs):\n",
    "    # sample_probability = (10 + epoch_index) / args.num_epochs\n",
    "    if epoch_index < 0.5 * args.num_epochs:\n",
    "        sample_probability = 0.05\n",
    "    else:\n",
    "        sample_probability = ( 2 * (epoch_index+1) - args.num_epochs) / args.num_epochs\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    model_zero.train()\n",
    "    \n",
    "    for batch_ind, rus_batch, rsl_batch in batch_generator(vec_sentences_rus_train, vec_sentences_rsl_train, args.batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        rus_batch = rus_batch.to(device)\n",
    "        rsl_batch = rsl_batch.to(device)\n",
    "        \n",
    "        y_pred = model_zero(rus_batch, rsl_batch, sample_probability)  # 0.0\n",
    "        y_pred = y_pred.to(device)\n",
    "        \n",
    "        loss = sequence_loss(y_pred, rsl_batch, args.mask_index)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        #nn.utils.clip_grad_value_(model_zero.parameters(), clip_value=1.0)\n",
    "        nn.utils.clip_grad_norm_(model_zero.parameters(), args.max_norm, args.norm_type)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += (loss.item() - running_loss) / (batch_ind + 1)\n",
    "        acc_t = compute_accuracy(y_pred, rsl_batch, args.mask_index)\n",
    "        \n",
    "    print('Epoch: ', epoch_index, 'Loss: ', running_loss, '\\tacc: ', acc_t, '\\tsample_prob: ', sample_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2304f42",
   "metadata": {
    "cellId": "fg1jv5vh42g3nahqjuhsgi"
   },
   "source": [
    "When sample probability started to grow, the model accuracy started to drop dramatically. Probably it's because this word order is totally random, and when the sample probability was super low, it overfit quickly, as soon as it started to rise, the model got confused with the random word order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe50fbad",
   "metadata": {
    "cellId": "xuqepkumtup0a2ci5vmp1yc"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "torch.save(model_zero.state_dict(), \"model30_gen_task_agnostic.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09280b20",
   "metadata": {
    "cellId": "v7u5b0ddlhtxmrjmnw35nh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Translator(\n",
       "  (encoder): TranslatorEncoder(\n",
       "    (rus_embeddings): Embedding(50350, 16, max_norm=1.0)\n",
       "    (rus_birnn): GRU(16, 64, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): TranslatorDecoder(\n",
       "    (rsl_embedding): Embedding(50757, 16, max_norm=1.0)\n",
       "    (gru_cell): GRUCell(144, 128)\n",
       "    (linear_map): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (classifier): Linear(in_features=256, out_features=50757, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1 \n",
    "model_zero.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "504748a4",
   "metadata": {
    "cellId": "zvz4x4869uhd4tveg5kvll"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import re\n",
    "\n",
    "\n",
    "regex = re.compile(r'(?:<bos>|<eos>.*)')\n",
    "def pred_vs_rsl(tensor, true_rsl, rus): \n",
    "    \n",
    "    tensor = tensor.argmax(2).tolist()\n",
    "    \n",
    "    pred_rsl = voc_rsl.index_to_text(tensor)\n",
    "    true_rsl = voc_rsl.index_to_text(true_rsl)\n",
    "    rus = voc_rus.index_to_text(rus)\n",
    "                   \n",
    "    f = lambda x: regex.sub('', \" \".join(x))\n",
    "                   \n",
    "    pred_rsl = [f(sentence) for sentence in pred_rsl]\n",
    "    true_rsl = [f(sentence) for sentence in true_rsl]\n",
    "    true_rus = [f(sentence) for sentence in rus]\n",
    "    \n",
    "    return pred_rsl, true_rsl, true_rus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "378c5553",
   "metadata": {
    "cellId": "s25npd3ddd810ow1qelz3j"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "vec_sentences_rus_test = voc_rus.text_to_index(list(test_data['test_stem_rus']))\n",
    "vec_gram_test = bin_gram.transform(list(test_data['test_gram_rus']))\n",
    "vec_sentences_rsl_test = voc_rsl.text_to_index(list(test_data['test_rsl']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917193ae",
   "metadata": {
    "cellId": "rdbb8u5zwggymm6h4zu0rn"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 140.00 MiB (GPU 0; 31.75 GiB total capacity; 30.23 GiB already allocated; 93.50 MiB free; 30.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-72071e2fb1f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec_sentences_rus_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrsl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec_sentences_rsl_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m y_pred = model_zero(rus,\n\u001b[0m\u001b[1;32m      4\u001b[0m                     rsl, 1).to_device  #0\n\u001b[1;32m      5\u001b[0m trans, truth_rsl, rus = pred_vs_rsl(y_pred,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/resources/Notebooks/../model/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, rus_sentances, rsl_sentence, sample_probability)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrus_sentances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsl_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mencoder_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrus_sentances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mdecoded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsl_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_probability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/resources/Notebooks/../model/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, rus_sentances)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# rus_rnn_h.shape = (rnn_size, batch_size, rus_emb_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mrus_birnn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrus_rnn_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrus_birnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrus_embedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m# permute to (batch_size, rnn_size, rus_emb_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mrus_rnn_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrus_rnn_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    943\u001b[0m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    944\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 140.00 MiB (GPU 0; 31.75 GiB total capacity; 30.23 GiB already allocated; 93.50 MiB free; 30.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "rus = torch.tensor(np.array(vec_sentences_rus_test)).to(device)\n",
    "rsl = torch.tensor(np.array(vec_sentences_rsl_test)).to(device)\n",
    "y_pred = model_zero(rus,\n",
    "                    rsl, 1).to_device  #0\n",
    "trans, truth_rsl, rus = pred_vs_rsl(y_pred,\n",
    "                                    rsl,\n",
    "                                    rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa65831c",
   "metadata": {
    "cellId": "rrc3yxsa8bqtycbisfgd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 460)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "voc_rus.word_count, voc_rsl.word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78e9af92",
   "metadata": {
    "cellId": "g9r3ay4fy99fknp6j01yid"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSL:   <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> приходить <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "TRANS:   и \n",
      "RUS:   а когда <unk> <unk> <unk> <unk> <unk> <unk> <unk> приходить к <unk> и сказать а <unk> то <unk> в <unk> <unk> <unk> <unk> \n",
      "\n",
      "\n",
      "RSL:   <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "TRANS:   и \n",
      "RUS:   а <unk> <unk> <unk> весь <unk> \n",
      "\n",
      "\n",
      "RSL:    \n",
      "TRANS:   \n",
      "RUS:   <unk> <unk> <unk> что <unk> быть в <unk> год у мы <unk> быть <unk> <unk> <unk> и это <unk> <unk> <unk> в себя в то <unk> и <unk> <unk> <unk> <unk> в другой <unk> \n",
      "\n",
      "\n",
      "RSL:    \n",
      "TRANS:    \n",
      "RUS:   <unk> <unk> <unk> <unk> <unk> свой <unk> по <unk> <unk> <unk> <unk> \n",
      "\n",
      "\n",
      "RSL:   <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> свой <unk> <unk> и <unk> <unk> \n",
      "TRANS:    \n",
      "RUS:   <unk> <unk> хотеть <unk> свой <unk> <unk> и начинать <unk> \n",
      "\n",
      "\n",
      "RSL:   <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "TRANS:    \n",
      "RUS:   <unk> <unk> это <unk> в <unk> \n",
      "\n",
      "\n",
      "RSL:   <unk> <unk> <unk> <unk> не <unk> \n",
      "TRANS:    \n",
      "RUS:   <unk> <unk> не <unk> <unk> \n",
      "\n",
      "\n",
      "RSL:    \n",
      "TRANS:   \n",
      "RUS:   это <unk> который <unk> <unk> <unk> в <unk> \n",
      "\n",
      "\n",
      "RSL:    \n",
      "TRANS:   \n",
      "RUS:   у он <unk> быть <unk> с <unk> который <unk> <unk> \n",
      "\n",
      "\n",
      "RSL:   <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> \n",
      "TRANS:   \n",
      "RUS:   она один за другой <unk> с себя <unk> и <unk> в один <unk> <unk> к <unk> и у <unk> от <unk> <unk> сердце \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "for i in range(10):\n",
    "    print(\"RSL: \", truth_rsl[i])\n",
    "    print(\"TRANS: \", trans[i])\n",
    "    print(\"RUS: \", rus[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4df44fbc",
   "metadata": {
    "cellId": "wl8v6k1w8jfu4ucll1fl3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Russian to RSL:  0.0\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "import sacrebleu\n",
    "\n",
    "rus_rsl_bleu = sacrebleu.corpus_bleu(trans, [truth_rsl])\n",
    "print(\"--------------------------\")\n",
    "print(\"Russian to RSL: \", rus_rsl_bleu.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e9d7ef8",
   "metadata": {
    "cellId": "120mk2hhz1cal3lllljprj"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# save results to file\n",
    "result_data = pd.DataFrame.from_dict({\"truth RSL\": truth_rsl, \"TRANS\": trans, \"RUS\": rus})\n",
    "result_data.to_csv('test_result_task_agnostic_seq2seq.csv', index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "992d0387-9df4-42f2-864b-f01c34639727",
  "notebookPath": "Notebooks/Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
