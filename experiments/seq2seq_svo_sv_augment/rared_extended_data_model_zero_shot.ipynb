{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "cxq3zud69vfl6wi2jlgwlq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "cellId": "dg7aij6y2buzjua5vmo6m",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymystem3 in /home/jupyter/.local/lib/python3.7/site-packages (0.2.0)\n",
      "Requirement already satisfied: requests in /kernel/lib/python3.7/site-packages (from pymystem3) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.7/site-packages (from requests->pymystem3) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /kernel/lib/python3.7/site-packages (from requests->pymystem3) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /kernel/lib/python3.7/site-packages (from requests->pymystem3) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jupyter/.local/lib/python3.7/site-packages (from requests->pymystem3) (1.25.11)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.7.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: razdel in /home/jupyter/.local/lib/python3.7/site-packages (0.5.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pympi-ling in /home/jupyter/.local/lib/python3.7/site-packages (1.70.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "%pip install pymystem3\n",
    "%pip install pymorphy2\n",
    "%pip install razdel\n",
    "%pip install pympi-ling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "xz2yeutuwk9cdwlqjsvz4k"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import re\n",
    "import pymystem3\n",
    "import os, sys\n",
    "sys.path.append('../')\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from argparse import Namespace\n",
    "\n",
    "from pyeaf.pyeaf import EAFReader\n",
    "from pyeaf.text import VocabularyVectorizer, TextStemmer, RSLStemmer, GramBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellId": "7yko210ertgjy50hwt9t8r"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyeaf.pyeaf.EAFReader at 0x7f17b17868b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "er = EAFReader(directory=\"../Разметки eaf\")\n",
    "er.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "81b774bquywyhldm2h0et"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "sentences_rus = er.get_sentences(er.RUS)\n",
    "sentences_rsl = er.get_sentences(er.RSL_R)\n",
    "\n",
    "# sentences_rsl_left = er.get_sentences(er.RSL_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellId": "xqfcroj8ohdt1llh20i2bp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['сегодня',\n",
       "  'время',\n",
       "  'слушать',\n",
       "  'добрый',\n",
       "  'и',\n",
       "  'милый',\n",
       "  'история',\n",
       "  'собирать',\n",
       "  'весь',\n",
       "  'мир',\n",
       "  'появляться'],\n",
       " ['пожарный',\n",
       "  'город',\n",
       "  'А-р-л-и-н-г-т-о-н',\n",
       "  'штат',\n",
       "  'В-е-р-д-ж-и-н-и-я',\n",
       "  'думать',\n",
       "  'необходимость',\n",
       "  'полезный',\n",
       "  'мероприятие',\n",
       "  'что',\n",
       "  'можно',\n",
       "  'придумывать',\n",
       "  'необычный']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "i = 0\n",
    "for rus, rsl in zip(sentences_rus, sentences_rsl):\n",
    "    if rsl == []:\n",
    "        #print(rsl)\n",
    "        #_, _ = sentences_rus.pop(i), sentences_rsl.pop(i)\n",
    "        del sentences_rus[i]\n",
    "        del sentences_rsl[i]\n",
    "    i += 1\n",
    "sentences_rsl[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellId": "0ootae6aub9kj1i3m9l44n"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "st = TextStemmer()\n",
    "\n",
    "stem_sentences_rus, gram_sentences_rus = st.stem(sentences_rus, gram=True)\n",
    "stem_sentences_rsl = list(map(RSLStemmer.stem_sentence, sentences_rsl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellId": "7pz9gyohuyfzhlocg5jro"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['сегодня',\n",
       "  'время',\n",
       "  'слушать',\n",
       "  'добрый',\n",
       "  'и',\n",
       "  'милый',\n",
       "  'история',\n",
       "  'собирать',\n",
       "  'весь',\n",
       "  'мир',\n",
       "  'появляться'],\n",
       " ['пожарный',\n",
       "  'город',\n",
       "  '<dact>',\n",
       "  'штат',\n",
       "  '<dact>',\n",
       "  'думать',\n",
       "  'необходимость',\n",
       "  'полезный',\n",
       "  'мероприятие',\n",
       "  'что',\n",
       "  'можно',\n",
       "  'придумывать',\n",
       "  'необычный']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "stem_sentences_rsl[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellId": "zad7o7n700jzxuj4m3nd1l"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3679"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "len(stem_sentences_rus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "bmam1jsupvq9j4oeyjypj"
   },
   "source": [
    "## Extended data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellId": "mtrmhba1lugicdjka5i2u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rared_fake_sents_place_adverbs_fake_data.tsv', 'rared_fake_sents_time_adverbs_fake_data.tsv', 'rared_fake_sents_rsl_sv.tsv', 'rared_fake_sents_move_adverbs_fake_data.tsv', 'rared_fake_sents_rsl_svo_45.tsv', 'rared_fake_sents_rsl_svo_33.tsv', 'rared_fake_sents_rsl_svo_47.tsv', 'rared_fake_sents_rsl_svo_34.tsv', 'rared_fake_sents_rsl_svo_39.tsv', 'rared_fake_sents_rsl_svo_35.tsv', 'rared_fake_sents_rsl_svo_37.tsv', 'rared_fake_sents_rsl_svo_50.tsv', 'rared_fake_sents_rsl_svo_49.tsv', 'rared_fake_sents_rsl_svo_42.tsv', 'rared_fake_sents_rsl_svo_32.tsv', 'rared_fake_sents_rsl_svo_31.tsv', 'rared_fake_sents_rsl_svo_48.tsv', 'rared_fake_sents_rsl_svo_36.tsv', 'rared_fake_sents_rsl_svo_30.tsv', 'rared_fake_sents_rsl_svo_40.tsv', 'rared_fake_sents_rsl_svo_46.tsv', 'rared_fake_sents_rsl_svo_43.tsv', 'rared_fake_sents_rsl_svo_44.tsv', 'rared_fake_sents_rsl_svo_38.tsv', 'rared_fake_sents_rsl_svo_41.tsv']\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "# readlines stem each line\n",
    "import pandas as pd\n",
    "\n",
    "sentences_rus_fake = []\n",
    "sentences_rsl_fake = []\n",
    "for _, d, files in os.walk('rared'):\n",
    "    print(files)\n",
    "    for file in files:\n",
    "        data = pd.read_csv('rared/' + file, sep='\\t', names=['rus', 'rsl'], encoding='utf-8')\n",
    "        sentences_rsl_fake.extend(data.rsl.tolist())\n",
    "        sentences_rus_fake.extend(data.rus.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellId": "xkagu2kiffm9etzskle3re"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950555\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "print(len(sentences_rsl_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellId": "3nw8mz5a8qyh5pckx03lku"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Мой друг сразу же не купил пальто.',\n",
       " 'Рано бывает такое, что действительно начальник готов взять человека с инвалидностью, но он не знает какую работу ему предложить',\n",
       " 'Они набрали взрослых детей уже закончивших школы, у которых не было русского языка.',\n",
       " 'Пожалуйста, поторопись, чтобы очереди не было.',\n",
       " 'Были попытки глухих уезжать в села, создавать совхозы.',\n",
       " 'Или, например, человек хочет после вставать, чтобы все успевать, но не может, потому что друзья его затягивают и вынуждают сидеть допоздна; получается, что виноваты они, но это не так.',\n",
       " 'Я поняла, что иногда думала, что образование не особо важно, но нет, оно необходимо.',\n",
       " 'Я это сразу в шутку называл город вогоград ',\n",
       " 'Регулярно глухие карманные часы.',\n",
       " 'Навсегда другое время было']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "sentences_rus_fake[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "rlpq0v6p837vz9yiwyqg7"
   },
   "source": [
    "Пробую отскорить классификатором предложения из 950 000 нагенерированных\n",
    "\n",
    "И взять только хорошие, выше 0.8 для начала\n",
    "\n",
    "Заодно я сохраняю скор для каждого предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellId": "9devbwqq9sx3t5ysx2gl"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellId": "nt233xy43kzlki1e392ep"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class Clf(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim):\n",
    "        \n",
    "        super().__init__()          \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.flatten = nn.Flatten() # вместо усреднения склеим все в 1 вектор\n",
    "        self.fc = nn.Linear(embedding_dim*MAX_LEN, output_dim) # размер склееного вектора - размер эмбединга на MAX_LEN\n",
    "        self.act = nn.Sigmoid() # активацию менять даже не пришлось, так как у нас бинарная классификация\n",
    "                                # если классов больше 2, то нужно поставить nn.Softmax()\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        embedded = self.embedding(text)   \n",
    "        hidden = self.flatten(embedded)\n",
    "        dense_outputs=self.fc(hidden)\n",
    "        outputs=self.act(dense_outputs) \n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellId": "osm1i0ajkm9wdreu8ref4h"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clf(\n",
       "  (embedding): Embedding(14250, 30)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc): Linear(in_features=2100, out_features=1, bias=True)\n",
       "  (act): Sigmoid()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "MAX_LEN = 70\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# load again the model that we saved\n",
    "model_clf = Clf(14250, 30, 1)\n",
    "model_clf.load_state_dict(torch.load(\"clf_simple.pt\"))\n",
    "model_clf.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellId": "pbr3qtuzkgjvrfzitvpje"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "filtered_vocab = torch.load('filtered_vocab.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellId": "l4jc5zfum8qv5egkkamd"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# индексируем слова\n",
    "word2id = {'PAD':0}\n",
    "\n",
    "for word in filtered_vocab:\n",
    "    word2id[word] = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellId": "8uodhhniwqia41oelm4yln"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clf(\n",
       "  (embedding): Embedding(14250, 30)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc): Linear(in_features=2100, out_features=1, bias=True)\n",
       "  (act): Sigmoid()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "def preprocess(text):\n",
    "    tokens = text.lower().split()\n",
    "    tokens = [token.strip(punctuation) for token in tokens]\n",
    "    tokens = [token for token in tokens if token]\n",
    "    return tokens\n",
    "\n",
    "def prepare_texts_to_pred(text):\n",
    "    # в index будут индексы от 0 до len(rsl_svo_50.rus) = len(data)\n",
    "    # по ним мы достанем тексты, предобработаем, переведем в векторы, западим и вернем\n",
    "    tokens = preprocess(text) # токенизируем\n",
    "    ids = [word2id[token] for token in tokens if token in word2id][:MAX_LEN]\n",
    "    ids = torch.nn.functional.pad(torch.LongTensor(ids), \n",
    "                                  (0, MAX_LEN-len(ids)), \n",
    "                                  mode='constant',\n",
    "                                  value=0)\n",
    "    return ids\n",
    "\n",
    "model_clf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cellId": "m802iudjdjde2uk4i0fp9h"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentences_rus_fake' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-af99d8c445aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rared_good_fake_sents.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrus\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_rus_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 950 000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_texts_to_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# single_pred = model(sent.unsqueeze(0).to(device)).detach().to('cpu').numpy().tolist()[0][0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msingle_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentences_rus_fake' is not defined"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# write\n",
    "with open('rared_good_fake_sents.tsv', 'w', encoding='utf-8') as f:\n",
    "    for i, rus in enumerate(tqdm(sentences_rus_fake)):  # 950 000\n",
    "        sent = prepare_texts_to_pred(rus)\n",
    "        # single_pred = model(sent.unsqueeze(0).to(device)).detach().to('cpu').numpy().tolist()[0][0]\n",
    "        single_pred = model(sent.unsqueeze(0)).detach().numpy().tolist()[0][0]\n",
    "        \n",
    "        # вообще лучший f1-score для класса хороших предожений был на 0.4\n",
    "        if single_pred > 0.5: \n",
    "            # print(rus, round(single_pred, 4))\n",
    "            f.write(rus + '\\t' + sentences_rsl_fake[i] + '\\t' + str(single_pred) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellId": "9b2pfgzmmzhmw4xd6vwfs"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rus</th>\n",
       "      <th>rsl</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Или, например, человек хочет после вставать, ч...</td>\n",
       "      <td>есть тоже люди кто желание после вставать2 что...</td>\n",
       "      <td>0.515437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Например, скоро, на предприятии вог, на швейно...</td>\n",
       "      <td>что скоро пример завод вог завод шить2 шить3 п...</td>\n",
       "      <td>0.517674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Да, мы после хотели.</td>\n",
       "      <td>indx желание после indx да :pl</td>\n",
       "      <td>0.519577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Вообще, мы рано думали что нужно добавить жест...</td>\n",
       "      <td>результат indx рано думать что необходимость ж...</td>\n",
       "      <td>0.517183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Дочь достигает.</td>\n",
       "      <td>Дочь достигать</td>\n",
       "      <td>0.507185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 rus  \\\n",
       "0  Или, например, человек хочет после вставать, ч...   \n",
       "1  Например, скоро, на предприятии вог, на швейно...   \n",
       "2                               Да, мы после хотели.   \n",
       "3  Вообще, мы рано думали что нужно добавить жест...   \n",
       "4                                    Дочь достигает.   \n",
       "\n",
       "                                                 rsl      pred  \n",
       "0  есть тоже люди кто желание после вставать2 что...  0.515437  \n",
       "1  что скоро пример завод вог завод шить2 шить3 п...  0.517674  \n",
       "2                     indx желание после indx да :pl  0.519577  \n",
       "3  результат indx рано думать что необходимость ж...  0.517183  \n",
       "4                                     Дочь достигать  0.507185  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "rared_good = pd.read_csv(\"rared_good_fake_sents.tsv\", sep=\"\\t\", names=['rus', 'rsl', 'pred'])\n",
    "rared_good.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellId": "j3jl6ixvubhulskll4kl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "len(rared_good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "m7rga5reaee0io55g6kzen"
   },
   "source": [
    "~ ~ ~ ~ ~\n",
    "\n",
    "Code below stems fake generated sentences. If the dataset is downloaded from file scroll a bit down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "cellId": "2wc1m0zrb17obk2lahogm8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to deserialize variable 'st'. Run the following code to delete it:\n",
      "  del_datasphere_variables('st')\n",
      "Traceback (most recent call last):\n",
      "  File \"/kernel/lib/python3.8/site-packages/ml_kernel/state/state_protocol.py\", line 283, in _load_component\n",
      "    value = unpickler.load()\n",
      "  File \"/kernel/lib/python3.8/site-packages/ipystate/impl/dispatch/common.py\", line 141, in _create_file\n",
      "    f = open(name, mode, encoding=encoding)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "ml_kernel.state.state_protocol.KernelStateProtocol.DeserializationException: ['st']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sentences_rsl_fake' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-25162a9bf233>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_rsl_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mstem_sentences_rsl_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentences_rsl_fake' is not defined"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "st = TextStemmer()\n",
    "\n",
    "length = len(sentences_rsl_fake)\n",
    "\n",
    "stem_sentences_rsl_fake = []\n",
    "for i in tqdm(range(0, length, 100000)):  # instead of second position -> length\n",
    "    #print(stem_sentences_rsl_fake)\n",
    "    batch = list(map(RSLStemmer.stem_sentence, sentences_rsl_fake[i:i+100000]))\n",
    "    stem_sentences_rsl_fake.extend(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellId": "uaka4vcn5kcbz7arsbzk45"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:01<00:00, 18.15s/it]\n",
      "/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:840: UserWarning: The following variables cannot be serialized: st\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "length = len(sentences_rus_fake)\n",
    "\n",
    "stem_sentences_rus_fake, gram_sentences_rus_fake = [], []\n",
    "for i in tqdm(range(0, length, 100000)):  # instead of second position -> length\n",
    "    #print(stem_sentences_rsl_fake)\n",
    "    batch_stem, batch_gram = st.stem(sentences_rus_fake[i:i+100000], gram=True)\n",
    "    stem_sentences_rus_fake.extend(batch_stem)\n",
    "    gram_sentences_rus_fake.extend(batch_gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "gjl791an7qnrtxeqzn21"
   },
   "source": [
    "### If data is loaded from file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellId": "c711ixx05mtunnnsckacbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    есть тоже люди кто желание после вставать2 что...\n",
       "1    что скоро пример завод вог завод шить2 шить3 п...\n",
       "2                       indx желание после indx да :pl\n",
       "Name: rsl, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "rared_good['rsl'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellId": "n8gzrd8globzbewpadv9i"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "st = TextStemmer()\n",
    "\n",
    "length = len(rared_good)\n",
    "\n",
    "stem_sentences_rsl_fake = []\n",
    "for i in tqdm(range(0, length, 100000)):  # instead of second position -> length\n",
    "    #print(stem_sentences_rsl_fake)\n",
    "    batch = list(map(RSLStemmer.stem_sentence, [el.split() for el in rared_good['rsl']][i:i+100000]))\n",
    "    stem_sentences_rsl_fake.extend(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cellId": "7sb7kcq41bmzkvj3ri9ah"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "stem_sentences_rus_fake, gram_sentences_rus_fake = [], []\n",
    "for i in tqdm(range(0, length, 100000)):  # instead of second position -> length\n",
    "    #print(stem_sentences_rsl_fake)\n",
    "    batch_stem, batch_gram = st.stem(rared_good['rus'][i:i+100000], gram=True)\n",
    "    stem_sentences_rus_fake.extend(batch_stem)\n",
    "    gram_sentences_rus_fake.extend(batch_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellId": "4d7of2qjp9mhnp9fu43m2n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['CONJ'],\n",
       "  ['ADV', 'вводн'],\n",
       "  ['вин', 'S', 'муж', 'мн', 'ед', 'им', 'род', 'од'],\n",
       "  ['несов', 'ед', 'V', '3-л', 'изъяв', 'непрош', 'пе'],\n",
       "  ['PR'],\n",
       "  ['нп', 'инф', 'несов', 'V'],\n",
       "  ['CONJ'],\n",
       "  ['вин', 'мн', 'неод', 'ед', 'им', 'сред', 'APRO'],\n",
       "  ['нп', 'инф', 'несов', 'V'],\n",
       "  ['CONJ'],\n",
       "  ['PART'],\n",
       "  ['несов', 'ед', 'V', '3-л', 'нп', 'изъяв', 'непрош'],\n",
       "  ['ADVPRO'],\n",
       "  ['CONJ'],\n",
       "  ['S', 'муж', 'мн', 'им', 'од'],\n",
       "  ['вин', 'муж', 'SPRO', '3-л', 'ед', 'род'],\n",
       "  ['несов', 'мн', '3-л', 'V', 'изъяв', 'непрош', 'пе'],\n",
       "  ['CONJ'],\n",
       "  ['несов', 'мн', '3-л', 'V', 'изъяв', 'непрош', 'пе'],\n",
       "  ['нп', 'инф', 'несов', 'V'],\n",
       "  ['ADV'],\n",
       "  ['несов', 'ед', 'V', '3-л', 'нп', 'изъяв', 'непрош'],\n",
       "  ['CONJ'],\n",
       "  ['A', 'мн', 'кр'],\n",
       "  ['им', 'SPRO', 'мн'],\n",
       "  ['CONJ'],\n",
       "  ['вин', 'неод', 'SPRO', 'ед', 'им', 'сред'],\n",
       "  ['PART'],\n",
       "  ['ADVPRO']],\n",
       " [['ADV', 'вводн'],\n",
       "  ['ADV'],\n",
       "  ['PR'],\n",
       "  ['S', 'неод', 'ед', 'пр', 'сред'],\n",
       "  ['жен', 'S', 'мн', 'неод', 'род'],\n",
       "  ['PR'],\n",
       "  ['жен', 'ед', 'твор', 'пр', 'A', 'род', 'полн', 'дат'],\n",
       "  ['жен', 'S', 'неод', 'ед', 'пр', 'дат'],\n",
       "  ['ADV', 'вводн'],\n",
       "  ['жен', 'S', 'мн', 'неод', 'род'],\n",
       "  ['несов', 'прош', 'ед', 'V', 'нп', 'сред', 'изъяв']]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "gram_sentences_rus_fake[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cellId": "iocxv3jlqg9zad3gxx2is"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['или',\n",
       "  'например',\n",
       "  'человек',\n",
       "  'хотеть',\n",
       "  'после',\n",
       "  'вставать',\n",
       "  'чтобы',\n",
       "  'весь',\n",
       "  'успевать',\n",
       "  'но',\n",
       "  'не',\n",
       "  'мочь',\n",
       "  'потому',\n",
       "  'что',\n",
       "  'друг',\n",
       "  'он',\n",
       "  'затягивать',\n",
       "  'и',\n",
       "  'вынуждать',\n",
       "  'сидеть',\n",
       "  'допоздна',\n",
       "  'получаться',\n",
       "  'что',\n",
       "  'виноватый',\n",
       "  'они',\n",
       "  'но',\n",
       "  'это',\n",
       "  'не',\n",
       "  'так'],\n",
       " ['например',\n",
       "  'скоро',\n",
       "  'на',\n",
       "  'предприятие',\n",
       "  'вога',\n",
       "  'на',\n",
       "  'швейный',\n",
       "  'фабрика',\n",
       "  'например',\n",
       "  'машинка',\n",
       "  'быть'],\n",
       " ['да', 'мы', 'после', 'хотеть'],\n",
       " ['вообще',\n",
       "  'мы',\n",
       "  'рано',\n",
       "  'думать',\n",
       "  'что',\n",
       "  'нужно',\n",
       "  'добавлять',\n",
       "  'жестовый',\n",
       "  'язык',\n",
       "  'и',\n",
       "  'это',\n",
       "  'решать',\n",
       "  'весь',\n",
       "  'проблема']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "stem_sentences_rus_fake[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cellId": "hciyevookhb151hynj8bi8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['есть',\n",
       "  'тоже',\n",
       "  'люди',\n",
       "  'кто',\n",
       "  'желание',\n",
       "  'после',\n",
       "  'вставать2',\n",
       "  'что',\n",
       "  'мочь2',\n",
       "  'все',\n",
       "  '<unk>',\n",
       "  'не',\n",
       "  'мочь',\n",
       "  'потому',\n",
       "  'что',\n",
       "  'человек',\n",
       "  'вчера',\n",
       "  '1ps',\n",
       "  'затягивать2',\n",
       "  '3ps',\n",
       "  'сидеть',\n",
       "  'поздно',\n",
       "  'успех',\n",
       "  'что',\n",
       "  'надеяться',\n",
       "  'indx',\n",
       "  'вина',\n",
       "  'знать',\n",
       "  'poss',\n",
       "  '3ps',\n",
       "  'indx',\n",
       "  'карьера',\n",
       "  'успех',\n",
       "  'успех',\n",
       "  'нет',\n",
       "  'общий',\n",
       "  'вина',\n",
       "  'indx'],\n",
       " ['что',\n",
       "  'скоро',\n",
       "  'пример',\n",
       "  'завод',\n",
       "  'вог',\n",
       "  'завод',\n",
       "  'шить2',\n",
       "  'шить3',\n",
       "  'пример',\n",
       "  'indx',\n",
       "  '<nums>',\n",
       "  'швейная.машина'],\n",
       " ['indx', 'желание', 'после', 'indx', 'да', 'pl'],\n",
       " ['результат',\n",
       "  'indx',\n",
       "  'рано',\n",
       "  'думать',\n",
       "  'что',\n",
       "  'необходимость',\n",
       "  'жестовый',\n",
       "  'язык',\n",
       "  'добавить',\n",
       "  'все',\n",
       "  'проблема2',\n",
       "  'решать']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "stem_sentences_rsl_fake[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "150wb172zwzmehxtmu5v7"
   },
   "source": [
    "## Put all data in one bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "cellId": "5lbimf45wl66khjfidwr7q"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# if loaded from memory\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train_rus, test_rus, train_rsl, test_rsl, train_gram_rus, test_gram_rus = train_test_split(stem_sentences_rus_fake,\n",
    "#                                                                                           stem_sentences_rsl_fake,\n",
    "#                                                                                           gram_sentences_rus_fake,\n",
    "#                                                                                           test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellId": "lpvkwon3sdo4qgchhk7xxu"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train_rus, test_rus, train_gram_rus, test_gram_rus, train_rsl, test_rsl = train_test_split(stem_sentences_rus + stem_sentences_rus_fake,\n",
    "#                                                                                           gram_sentences_rus + gram_sentences_rus_fake,\n",
    "#                                                                                           stem_sentences_rsl + stem_sentences_rsl_fake,\n",
    "#                                                                                           test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cellId": "uvxssggpkqxc6rayah8fq"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import json\n",
    "\n",
    "test_data = pd.read_csv('test_data.csv', encoding='utf-8')\n",
    "\n",
    "test_data['test_stem_rus'] = test_data['test_stem_rus'].apply(lambda sent: sent.strip('[]\\'').split('\\', \\''))\n",
    "test_data['test_rsl'] = test_data['test_rsl'].apply(lambda sent: sent.strip('[]\\'').split('\\', \\''))\n",
    "test_data['test_gram_rus'] = test_data['test_gram_rus'].apply(lambda sent: json.loads(sent.replace('\\'', '\\\"')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cellId": "8bcdwp9svciwvdfrxjldc"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "voc_rus = VocabularyVectorizer(phrase_border=True)\n",
    "bin_gram = GramBinarizer(phrase_border=True)\n",
    "voc_rsl = VocabularyVectorizer(phrase_border=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cellId": "fakj0x4ua42o3gsrzyqwl"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "voc_rus = voc_rus.fit(stem_sentences_rus_fake + list(test_data['test_stem_rus']))\n",
    "bin_gram = bin_gram.fit(gram_sentences_rus_fake + list(test_data['test_gram_rus']))\n",
    "voc_rsl = voc_rsl.fit(stem_sentences_rsl_fake + list(test_data['test_rsl']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cellId": "zsmb1qnsvxg40unnlpii6d"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "vec_sentences_rus_train = voc_rus.text_to_index(stem_sentences_rus_fake)\n",
    "vec_gram_train = bin_gram.transform(gram_sentences_rus_fake)\n",
    "vec_sentences_rsl_train = voc_rsl.text_to_index(stem_sentences_rsl_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cellId": "uwwoe6kqmhhyfjz5cpmy2"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "words = [w for s in list(test_data['test_rsl']) + stem_sentences_rsl_fake for w in s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "xnz9iqhiwf1qaxpm7wgat"
   },
   "source": [
    "## Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cellId": "ch8i8ft2845mv635g99hn"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from model.model import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cellId": "loesuglyajds1prgnsqos"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "    \n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "         \n",
    "        # If loss worsened\n",
    "        if loss_t >= loss_tm1:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def normalize_sizes(y_pred, y_true):\n",
    "    \"\"\"Normalize tensor sizes\n",
    "    \n",
    "    Args:\n",
    "        y_pred (torch.Tensor): the output of the model\n",
    "            If a 3-dimensional tensor, reshapes to a matrix\n",
    "        y_true (torch.Tensor): the target predictions\n",
    "            If a matrix, reshapes to be a vector\n",
    "    \"\"\"\n",
    "    if len(y_pred.size()) == 3:\n",
    "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n",
    "    if len(y_true.size()) == 2:\n",
    "        y_true = y_true.contiguous().view(-1)\n",
    "    return y_pred, y_true\n",
    "\n",
    "def compute_accuracy(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    \n",
    "    correct_indices = torch.eq(y_pred_indices, y_true).float()\n",
    "    valid_indices = torch.ne(y_true, mask_index).float()\n",
    "    \n",
    "    n_correct = (correct_indices * valid_indices).sum().item()\n",
    "    n_valid = valid_indices.sum().item()\n",
    "\n",
    "    return n_correct / n_valid * 100\n",
    "\n",
    "def sequence_loss(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cellId": "jwej4714bbpkp6iom68ha"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import random \n",
    "\n",
    "def batch_generator(rus_data, rsl_data, batch_size=32):\n",
    "    rus_data = np.array(rus_data)\n",
    "    rsl_data = np.array(rsl_data)\n",
    "    \n",
    "    data_length = len(rus_data)\n",
    "    tail_length = batch_size - data_length % batch_size\n",
    "    index = list(range(data_length))\n",
    "    random.shuffle(index)\n",
    "    \n",
    "    index = np.array(index + random.choices(index, k=tail_length))\n",
    "    num_batches = len(index) // batch_size\n",
    "    index = index.reshape((num_batches, batch_size))\n",
    "    \n",
    "    for batch_ind, inds in enumerate(tqdm(index)):\n",
    "        yield batch_ind, torch.tensor(rus_data[inds]), torch.tensor(rsl_data[inds])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "vc6fma3rwmdzmz3h5tau4"
   },
   "source": [
    "## Load model \\ train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cellId": "goluuqm19cc4no9zl7rj86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cellId": "gwsefekc9aj0pdfshzto"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Translator(\n",
       "  (encoder): TranslatorEncoder(\n",
       "    (rus_embeddings): Embedding(5670, 16, max_norm=1.0)\n",
       "    (rus_birnn): GRU(16, 64, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): TranslatorDecoder(\n",
       "    (rsl_embedding): Embedding(5103, 16, max_norm=1.0)\n",
       "    (gru_cell): GRUCell(144, 128)\n",
       "    (linear_map): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (classifier): Linear(in_features=256, out_features=5103, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "# Model class must be defined somewhere\n",
    "# this is old\n",
    "# model = torch.load('rared_data_model.pth', map_location=device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cellId": "wsxfwuicmmrkspuw3qubq"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from argparse import Namespace\n",
    "\n",
    "args = Namespace(\n",
    "    seed = 1337,\n",
    "    learning_rate = 5e-4, \n",
    "    batch_size = 64,  # 64\n",
    "    num_epochs = 30,  # 30\n",
    "    rus_emb_size = 16,  # 16\n",
    "    rsl_emb_size = 16,  # 16\n",
    "    rnn_size = 64,  # 64\n",
    "    early_stopping_criteria = 5,\n",
    "    mask_index = voc_rsl.mask_ind,\n",
    "    max_norm = 2.0,\n",
    "    norm_type = 2\n",
    ")\n",
    "\n",
    "set_seed_everywhere(args.seed, torch.cuda.is_available())\n",
    "\n",
    "model_zero = Translator(voc_rus.word_count, args.rus_emb_size, voc_rsl.word_count, args.rsl_emb_size, args.rnn_size, voc_rsl.bos_ind)\n",
    "\n",
    "optimizer = optim.Adam(model_zero.parameters(), lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cellId": "ngj4j3s0pdlx93fmvj8k2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Translator(\n",
       "  (encoder): TranslatorEncoder(\n",
       "    (rus_embeddings): Embedding(4133, 16, max_norm=1.0)\n",
       "    (rus_birnn): GRU(16, 64, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): TranslatorDecoder(\n",
       "    (rsl_embedding): Embedding(3589, 16, max_norm=1.0)\n",
       "    (gru_cell): GRUCell(144, 128)\n",
       "    (linear_map): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (classifier): Linear(in_features=256, out_features=3589, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "model_zero.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cellId": "eb38ozky54dn0xewqoi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:18<00:00, 16.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Loss:  4.1932999397367725 \tacc:  44.10112359550562 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:18<00:00, 16.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Loss:  3.106593863329903 \tacc:  56.022408963585434 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:18<00:00, 16.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2 Loss:  2.6191964623101236 \tacc:  59.65909090909091 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:18<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3 Loss:  2.225509939370331 \tacc:  66.95156695156696 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:18<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4 Loss:  1.8604330358280476 \tacc:  68.81720430107528 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:18<00:00, 16.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5 Loss:  1.6033261263812022 \tacc:  78.30985915492957 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:18<00:00, 16.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6 Loss:  1.3201032539810795 \tacc:  85.47486033519553 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:18<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7 Loss:  1.1543317999101244 \tacc:  85.07042253521126 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:18<00:00, 16.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8 Loss:  0.97944244110223 \tacc:  89.85915492957747 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:18<00:00, 16.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9 Loss:  0.873351387905352 \tacc:  91.26760563380282 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:18<00:00, 16.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10 Loss:  0.7677313652303485 \tacc:  92.95774647887323 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:18<00:00, 16.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11 Loss:  0.6745534044524233 \tacc:  95.54317548746518 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:18<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12 Loss:  0.6108349682104702 \tacc:  95.48022598870057 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:18<00:00, 16.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  13 Loss:  0.5425972345501487 \tacc:  95.65217391304348 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:18<00:00, 16.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  14 Loss:  0.4786131826514746 \tacc:  95.77464788732394 \tsample_prob:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:18<00:00, 15.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  15 Loss:  0.5288075274891321 \tacc:  95.77464788732394 \tsample_prob:  0.06666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:18<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16 Loss:  0.8628978812032274 \tacc:  97.49303621169916 \tsample_prob:  0.13333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:18<00:00, 15.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  17 Loss:  0.9782558206707139 \tacc:  80.3921568627451 \tsample_prob:  0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:19<00:00, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  18 Loss:  1.1851290413727267 \tacc:  44.57142857142857 \tsample_prob:  0.26666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:19<00:00, 15.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19 Loss:  1.2812967357611418 \tacc:  96.045197740113 \tsample_prob:  0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:19<00:00, 15.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  20 Loss:  1.3501755457735218 \tacc:  67.67123287671232 \tsample_prob:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:19<00:00, 14.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  21 Loss:  1.5735436483264376 \tacc:  49.58217270194986 \tsample_prob:  0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:19<00:00, 14.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  22 Loss:  1.683925092772201 \tacc:  63.988919667590025 \tsample_prob:  0.5333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:20<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  23 Loss:  1.7896816128432138 \tacc:  83.69565217391305 \tsample_prob:  0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:20<00:00, 14.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  24 Loss:  1.9529637962780424 \tacc:  92.28650137741047 \tsample_prob:  0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:20<00:00, 14.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  25 Loss:  2.0209580792321113 \tacc:  52.07756232686981 \tsample_prob:  0.7333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:20<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  26 Loss:  2.1170723339925286 \tacc:  64.85714285714286 \tsample_prob:  0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:20<00:00, 14.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  27 Loss:  2.1036467120703644 \tacc:  58.791208791208796 \tsample_prob:  0.8666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:21<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  28 Loss:  2.119871574218827 \tacc:  58.620689655172406 \tsample_prob:  0.9333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:21<00:00, 13.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  29 Loss:  2.067997720907832 \tacc:  60.05586592178771 \tsample_prob:  1.0\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# train\n",
    "for epoch_index in range(args.num_epochs):\n",
    "    # sample_probability = (10 + epoch_index) / args.num_epochs\n",
    "    if epoch_index < 0.5 * args.num_epochs:\n",
    "        sample_probability = 0.05\n",
    "    else:\n",
    "        sample_probability = ( 2 * (epoch_index+1) - args.num_epochs) / args.num_epochs\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    model_zero.train()\n",
    "    \n",
    "    for batch_ind, rus_batch, rsl_batch in batch_generator(vec_sentences_rus_train, vec_sentences_rsl_train, args.batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        rus_batch = rus_batch.to(device)\n",
    "        rsl_batch = rsl_batch.to(device)\n",
    "        \n",
    "        y_pred = model_zero(rus_batch, rsl_batch, sample_probability)  # 0.0\n",
    "        y_pred = y_pred.to(device)\n",
    "        \n",
    "        loss = sequence_loss(y_pred, rsl_batch, args.mask_index)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        #nn.utils.clip_grad_value_(model_zero.parameters(), clip_value=1.0)\n",
    "        nn.utils.clip_grad_norm_(model_zero.parameters(), args.max_norm, args.norm_type)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += (loss.item() - running_loss) / (batch_ind + 1)\n",
    "        acc_t = compute_accuracy(y_pred, rsl_batch, args.mask_index)\n",
    "        \n",
    "    print('Epoch: ', epoch_index, 'Loss: ', running_loss, '\\tacc: ', acc_t, '\\tsample_prob: ', sample_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cellId": "wsttwp387nsr7539sq3u9"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "torch.save(model_zero.state_dict(), \"rared_data_model_sample_prob_zero_shot.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cellId": "tsvj9doi6cp598osg0gehd"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Save\\load vocabs\n",
    "import pickle\n",
    "\n",
    "def save_vocab(vocab, path):\n",
    "    output = open(path, 'wb')\n",
    "    pickle.dump(vocab, output)\n",
    "    output.close()\n",
    "    \n",
    "def load_vocab(path):\n",
    "    output = open(path, 'rb')\n",
    "    vocab = pickle.load(output)\n",
    "    output.close()\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cellId": "jdfgnt6egxnpa6lpahxpr9"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "save_vocab(voc_rus, 'voc_rus3.pkl')\n",
    "save_vocab(bin_gram, 'bin_gram3.pkl')\n",
    "save_vocab(voc_rsl, 'voc_rsl3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "cellId": "qx62kfhbzdr106ih6elvzkj"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Load vocabs\n",
    "#voc_rus = load_vocab('voc_rus3.pkl')\n",
    "#bin_gram = load_vocab('bin_gram3.pkl')\n",
    "#voc_rsl = load_vocab('voc_rsl3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "fz6poqoqwipit2xog16nd"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cellId": "y7u4ghc3fw0csql7av4mq5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Translator(\n",
       "  (encoder): TranslatorEncoder(\n",
       "    (rus_embeddings): Embedding(4133, 16, max_norm=1.0)\n",
       "    (rus_birnn): GRU(16, 64, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): TranslatorDecoder(\n",
       "    (rsl_embedding): Embedding(3589, 16, max_norm=1.0)\n",
       "    (gru_cell): GRUCell(144, 128)\n",
       "    (linear_map): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (classifier): Linear(in_features=256, out_features=3589, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "model_zero.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cellId": "iqkonlpyigo4buxkcpjmg"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "vec_gram_test = bin_gram.transform(list(test_data['test_gram_rus']))\n",
    "vec_sentences_rsl_test = voc_rsl.text_to_index(list(test_data['test_rsl']))\n",
    "vec_sentences_rus_test = voc_rus.text_to_index(list(test_data['test_stem_rus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cellId": "7hbymlr1mlx5ppiwqju6qs"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "#####\n",
    "regex = re.compile(r'(?:<bos>|<eos>.*)')\n",
    "def pred_vs_rsl(tensor, true_rsl): #, rus):\n",
    "    \n",
    "    tensor = tensor.argmax(2).tolist()\n",
    "    \n",
    "    pred_rsl = voc_rsl.index_to_text(tensor)\n",
    "    true_rsl = voc_rsl.index_to_text(true_rsl)\n",
    "    #rus = voc_rus.index_to_text(rus)\n",
    "                   \n",
    "    f = lambda x: regex.sub('', \" \".join(x))\n",
    "                   \n",
    "    pred_rsl = (f(sentence) for sentence in pred_rsl)\n",
    "    true_rsl = (f(sentence) for sentence in true_rsl)\n",
    "    #true_rus = (f(sentence) for sentence in rus)\n",
    "    \n",
    "    return pred_rsl, true_rsl #, true_rus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cellId": "qgfbukaiefkl8clyzn4vrf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]<ipython-input-41-e0189e923838>:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  t_sentences_rus_test_batch = torch.tensor(rus_test_batch).to(device)\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: trans_batch, truth_rsl_batch\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "length = len(vec_sentences_rus_test) - 1000  # 190 765\n",
    "\n",
    "trans, truth_rsl = [], []\n",
    "for i in tqdm(range(0, length, 1000)):\n",
    "    rus_test_batch = vec_sentences_rus_test[i:i+1000]\n",
    "    rsl_test_batch = vec_sentences_rsl_test[i:i+1000]\n",
    "    t_sentences_rus_test_batch = torch.tensor(rus_test_batch).to(device)\n",
    "    t_sentences_rsl_test_batch = torch.tensor(rsl_test_batch).to(device)\n",
    "    \n",
    "    y_pred_batch = []\n",
    "    for j in range(0, 1000, 100):\n",
    "        y_pred_batch.append(model_zero(t_sentences_rus_test_batch[j:j+100], t_sentences_rsl_test_batch[j:j+100], 0).to(device))\n",
    "    y_pred_batch = torch.cat(y_pred_batch, dim=1)\n",
    "    \n",
    "    trans_batch, truth_rsl_batch = pred_vs_rsl(y_pred_batch, t_sentences_rsl_test_batch)  #, t_sentences_rus_test_batch)\n",
    "    for el_trans, el_truth in zip(trans_batch, truth_rsl_batch):\n",
    "        truth_rsl.append(el_truth)\n",
    "        trans.append(el_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cellId": "wscqleq45s9em4ohbi5zyu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' indx дед.мороз clf clf.группа clf.переместить домой clf clf.группа clf.переместить дед.мороз маленький встретить приходить обращение главный 1ps был лес подарок clf clf.перечислять '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "truth_rsl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "cellId": "ulkub0msk182cty427k8i4"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "#trans, truth_rsl, rus = pred_vs_rsl(y_pred, torch.tensor(vec_sentences_rsl_test), torch.tensor(vec_sentences_rus_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cellId": "uyqj7mf0zuj0hb8buvrhb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSL:   indx дед.мороз clf clf.группа clf.переместить домой clf clf.группа clf.переместить дед.мороз маленький встретить приходить обращение главный 1ps был лес подарок clf clf.перечислять \n",
      "TRANS:   осёл держать дерево \n",
      "\n",
      "\n",
      "RSL:   мама второй 3ps все радость давать 1ps ноль \n",
      "TRANS:   свинья иметь адрес \n",
      "\n",
      "\n",
      "RSL:    \n",
      "TRANS:   стрелец бить на касательная \n",
      "\n",
      "\n",
      "RSL:    \n",
      "TRANS:   студент рвать разворот мат \n",
      "\n",
      "\n",
      "RSL:   зачем желание изменение все4 привычка тратить все4 желание именение привычка свой изменение тратить и копить думать \n",
      "TRANS:   судья разделять адрес \n",
      "\n",
      "\n",
      "RSL:   америка есть poss 3ps 3ps рассказ 1ps интересный америка первый прогресс \n",
      "TRANS:   панк исключать искоса дата \n",
      "\n",
      "\n",
      "RSL:   1ps вчера стирать <dact> не был \n",
      "TRANS:   родители вызвать адрес \n",
      "\n",
      "\n",
      "RSL:    \n",
      "TRANS:   студент смотреть искоса материал \n",
      "\n",
      "\n",
      "RSL:    \n",
      "TRANS:   студент смотреть искоса пассажирский \n",
      "\n",
      "\n",
      "RSL:   обувь2 убирать чулок бродить дверь 1ps думать радость 3ps скоро открывать.дверь сейчас скоро радость сердцебиение \n",
      "TRANS:   мы испытывать наслаждение касательная мат \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "for i in range(10):\n",
    "    print(\"RSL: \", truth_rsl[i])\n",
    "    print(\"TRANS: \", trans[i])\n",
    "    #print(\"RUS: \", rus[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cellId": "h5emo8ghj7988ojtwgbz6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "len(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "3q0vn1lp7qobvtsi901py"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "cellId": "bcug48wn03iadm51g5xxi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Russian to RSL:  20.32964662878887\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "import sacrebleu\n",
    "\n",
    "rus_rsl_bleu = sacrebleu.corpus_bleu(trans, [truth_rsl])\n",
    "print(\"--------------------------\")\n",
    "print(\"Russian to RSL: \", rus_rsl_bleu.score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "3837013e-b3b6-47e8-8540-d0957ff60df4",
  "notebookPath": "Notebooks/rared_extended_data_model.ipynb",
  "ydsNotebookPath": "Notebooks/rared_extended_data_model.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
