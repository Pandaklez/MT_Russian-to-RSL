{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93185ca4",
   "metadata": {
    "cellId": "9h276qvelssw2oclulhkx"
   },
   "source": [
    "## Which tokens affect classifier constructions the most?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d2608f",
   "metadata": {
    "cellId": "qrirg6pa41qcdokgfqw8ik"
   },
   "source": [
    "Load the best model from data augmentation experiments and the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40574882",
   "metadata": {
    "cellId": "2o72x8162uq8l288ai5b2k"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchtext.vocab as vocab\n",
    "import torch\n",
    "from razdel import sentenize\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320e8d1d",
   "metadata": {
    "cellId": "yx9ph4j3mu5y5v3jnfrgv"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from simpletransformers.t5 import T5Model, T5Args\n",
    "\n",
    "use_cuda = True\n",
    "\n",
    "model_args = T5Args()\n",
    "model_args.special_tokens_list = [\"clf\", \"poss\", \"sg\", \"<nums>\", \"<dact>\", \"1ps\", \"2ps\", \"3ps\", \"indx\", \"pl\"]\n",
    "model_args.max_seq_length = 96\n",
    "model_args.train_batch_size = 30\n",
    "model_args.eval_batch_size = 30\n",
    "model_args.num_train_epochs = 15\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.evaluate_during_training_steps = 30000\n",
    "model_args.use_multiprocessing = False\n",
    "model_args.fp16 = False\n",
    "model_args.save_steps = -1\n",
    "model_args.save_eval_checkpoints = False\n",
    "model_args.no_cache = True\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.preprocess_inputs = False\n",
    "model_args.num_return_sequences = 1\n",
    "model_args.wandb_project = \"MT5 Russian-RSL Translation\"\n",
    "\n",
    "model = T5Model(\"mt5\", \"outputs/best_model\", args=model_args)  #model15_special_tokens_mix_all.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aca69e",
   "metadata": {
    "cellId": "c2jmgmlhpbk2dp4bdskvw"
   },
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e38272b",
   "metadata": {
    "cellId": "mf8pwqjpgcbhzwd1yv4yx"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "test_data = pd.read_csv('test_data.csv', encoding='utf-8')\n",
    "\n",
    "test_data['stem_rus'] = test_data['test_stem_rus'].apply(lambda sent: sent.strip('[]\\'').split('\\', \\''))\n",
    "test_data['rsl'] = test_data['test_rsl'].apply(lambda sent: sent.strip('[]\\'').split('\\', \\''))\n",
    "test_data['gram_rus'] = test_data['test_gram_rus'].apply(lambda sent: json.loads(sent.replace('\\'', '\\\"')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed441c2e",
   "metadata": {
    "cellId": "7na18bwxc1jcytukgs36xq"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "for index, row in test_data.iterrows():\n",
    "    if row['rsl'] == ['']:\n",
    "        test_data.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44ba4c02",
   "metadata": {
    "cellId": "b8q8ufhd04jbj35fjf6mco"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "test_data['input_text'] = test_data['stem_rus'].apply(' '.join)\n",
    "test_data['target_text'] = test_data['rsl'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b7421d8",
   "metadata": {
    "cellId": "5nlelld47ctzsmko0j8ohp"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_stem_rus</th>\n",
       "      <th>test_gram_rus</th>\n",
       "      <th>test_rsl</th>\n",
       "      <th>stem_rus</th>\n",
       "      <th>rsl</th>\n",
       "      <th>gram_rus</th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['а', 'когда', 'дед', 'мороз', 'вернуться', 'д...</td>\n",
       "      <td>[['CONJ'], ['CONJ'], ['им', 'мн', 'S', 'муж', ...</td>\n",
       "      <td>['indx', 'дед.мороз', 'clf', 'clf.группа', 'cl...</td>\n",
       "      <td>[а, когда, дед, мороз, вернуться, домой, мален...</td>\n",
       "      <td>[indx, дед.мороз, clf, clf.группа, clf.перемес...</td>\n",
       "      <td>[[CONJ], [CONJ], [им, мн, S, муж, од], [им, мн...</td>\n",
       "      <td>а когда дед мороз вернуться домой маленький де...</td>\n",
       "      <td>indx дед.мороз clf clf.группа clf.переместить ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['а', 'мачеха', 'лишать', 'я', 'весь', 'радость']</td>\n",
       "      <td>[['CONJ'], ['им', 'S', 'од', 'жен', 'ед'], ['и...</td>\n",
       "      <td>['мама', 'второй', '3ps', 'все', 'радость', 'д...</td>\n",
       "      <td>[а, мачеха, лишать, я, весь, радость]</td>\n",
       "      <td>[мама, второй, 3ps, все, радость, давать, 1ps,...</td>\n",
       "      <td>[[CONJ], [им, S, од, жен, ед], [изъяв, V, пе, ...</td>\n",
       "      <td>а мачеха лишать я весь радость</td>\n",
       "      <td>мама второй 3ps все радость давать 1ps ноль</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['зачем', 'я', 'хотеть', 'изменять', 'свой', '...</td>\n",
       "      <td>[['ADVPRO'], ['им', 'ед', '1-л', 'SPRO'], ['из...</td>\n",
       "      <td>['зачем', 'желание', 'изменение', 'все4', 'при...</td>\n",
       "      <td>[зачем, я, хотеть, изменять, свой, привычка, т...</td>\n",
       "      <td>[зачем, желание, изменение, все4, привычка, тр...</td>\n",
       "      <td>[[ADVPRO], [им, ед, 1-л, SPRO], [изъяв, V, пе,...</td>\n",
       "      <td>зачем я хотеть изменять свой привычка тратить ...</td>\n",
       "      <td>зачем желание изменение все4 привычка тратить ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['оказываться', 'впервые', 'это', 'появляться'...</td>\n",
       "      <td>[['изъяв', 'V', '3-л', 'нп', 'несов', 'ед', 'н...</td>\n",
       "      <td>['америка', 'есть', 'poss', '3ps', '3ps', 'рас...</td>\n",
       "      <td>[оказываться, впервые, это, появляться, в, аме...</td>\n",
       "      <td>[америка, есть, poss, 3ps, 3ps, рассказ, 1ps, ...</td>\n",
       "      <td>[[изъяв, V, 3-л, нп, несов, ед, непрош], [ADV]...</td>\n",
       "      <td>оказываться впервые это появляться в америка</td>\n",
       "      <td>америка есть poss 3ps 3ps рассказ 1ps интересн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['я', 'вчера', 'не', 'стирать', 'белье']</td>\n",
       "      <td>[['им', 'ед', '1-л', 'SPRO'], ['ADV'], ['PART'...</td>\n",
       "      <td>['1ps', 'вчера', 'стирать', '&lt;dact&gt;', 'не', 'б...</td>\n",
       "      <td>[я, вчера, не, стирать, белье]</td>\n",
       "      <td>[1ps, вчера, стирать, &lt;dact&gt;, не, был]</td>\n",
       "      <td>[[им, ед, 1-л, SPRO], [ADV], [PART], [изъяв, V...</td>\n",
       "      <td>я вчера не стирать белье</td>\n",
       "      <td>1ps вчера стирать &lt;dact&gt; не был</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       test_stem_rus  \\\n",
       "0  ['а', 'когда', 'дед', 'мороз', 'вернуться', 'д...   \n",
       "1  ['а', 'мачеха', 'лишать', 'я', 'весь', 'радость']   \n",
       "4  ['зачем', 'я', 'хотеть', 'изменять', 'свой', '...   \n",
       "5  ['оказываться', 'впервые', 'это', 'появляться'...   \n",
       "6           ['я', 'вчера', 'не', 'стирать', 'белье']   \n",
       "\n",
       "                                       test_gram_rus  \\\n",
       "0  [['CONJ'], ['CONJ'], ['им', 'мн', 'S', 'муж', ...   \n",
       "1  [['CONJ'], ['им', 'S', 'од', 'жен', 'ед'], ['и...   \n",
       "4  [['ADVPRO'], ['им', 'ед', '1-л', 'SPRO'], ['из...   \n",
       "5  [['изъяв', 'V', '3-л', 'нп', 'несов', 'ед', 'н...   \n",
       "6  [['им', 'ед', '1-л', 'SPRO'], ['ADV'], ['PART'...   \n",
       "\n",
       "                                            test_rsl  \\\n",
       "0  ['indx', 'дед.мороз', 'clf', 'clf.группа', 'cl...   \n",
       "1  ['мама', 'второй', '3ps', 'все', 'радость', 'д...   \n",
       "4  ['зачем', 'желание', 'изменение', 'все4', 'при...   \n",
       "5  ['америка', 'есть', 'poss', '3ps', '3ps', 'рас...   \n",
       "6  ['1ps', 'вчера', 'стирать', '<dact>', 'не', 'б...   \n",
       "\n",
       "                                            stem_rus  \\\n",
       "0  [а, когда, дед, мороз, вернуться, домой, мален...   \n",
       "1              [а, мачеха, лишать, я, весь, радость]   \n",
       "4  [зачем, я, хотеть, изменять, свой, привычка, т...   \n",
       "5  [оказываться, впервые, это, появляться, в, аме...   \n",
       "6                     [я, вчера, не, стирать, белье]   \n",
       "\n",
       "                                                 rsl  \\\n",
       "0  [indx, дед.мороз, clf, clf.группа, clf.перемес...   \n",
       "1  [мама, второй, 3ps, все, радость, давать, 1ps,...   \n",
       "4  [зачем, желание, изменение, все4, привычка, тр...   \n",
       "5  [америка, есть, poss, 3ps, 3ps, рассказ, 1ps, ...   \n",
       "6             [1ps, вчера, стирать, <dact>, не, был]   \n",
       "\n",
       "                                            gram_rus  \\\n",
       "0  [[CONJ], [CONJ], [им, мн, S, муж, од], [им, мн...   \n",
       "1  [[CONJ], [им, S, од, жен, ед], [изъяв, V, пе, ...   \n",
       "4  [[ADVPRO], [им, ед, 1-л, SPRO], [изъяв, V, пе,...   \n",
       "5  [[изъяв, V, 3-л, нп, несов, ед, непрош], [ADV]...   \n",
       "6  [[им, ед, 1-л, SPRO], [ADV], [PART], [изъяв, V...   \n",
       "\n",
       "                                          input_text  \\\n",
       "0  а когда дед мороз вернуться домой маленький де...   \n",
       "1                     а мачеха лишать я весь радость   \n",
       "4  зачем я хотеть изменять свой привычка тратить ...   \n",
       "5       оказываться впервые это появляться в америка   \n",
       "6                           я вчера не стирать белье   \n",
       "\n",
       "                                         target_text  \n",
       "0  indx дед.мороз clf clf.группа clf.переместить ...  \n",
       "1        мама второй 3ps все радость давать 1ps ноль  \n",
       "4  зачем желание изменение все4 привычка тратить ...  \n",
       "5  америка есть poss 3ps 3ps рассказ 1ps интересн...  \n",
       "6                    1ps вчера стирать <dact> не был  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c0dfbd",
   "metadata": {
    "cellId": "rzu2vy6no1s9bx8sh5emf8"
   },
   "source": [
    "Try predicting something:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f535557e",
   "metadata": {
    "cellId": "3y9g6c1ue42002dza49dnopy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Я умею переводить текст на русский жестовый язык.',\n",
       " 'Этот текст перевела модель машинного перевода.',\n",
       " 'Дети играли в мяч на улице.',\n",
       " 'Получается довольно-таки глупо']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "text = \"\"\"\n",
    "    Я умею переводить текст на русский жестовый язык.\n",
    "    Этот текст перевела модель машинного перевода.\n",
    "    Дети играли в мяч на улице.\n",
    "    Получается довольно-таки глупо\n",
    "    \"\"\"\n",
    "to_rsl = [_.text for _ in list(sentenize(text))]\n",
    "to_rsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "356e5236",
   "metadata": {
    "cellId": "chlwwl15o25b98bjxlb35e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0893d32256764af6b15038fe5e6b1108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3538: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff6ef5ecc4642f08ec189bc0be12dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decoding outputs:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "rsl_preds = model.predict(to_rsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30b24203",
   "metadata": {
    "cellId": "gxwbl3gnpyz9u3msijj7h"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['я знать переводить текст на русский жестовый язык',\n",
       " 'перевести текст перевод модель этот машинный перевод',\n",
       " 'ребенок играть мяч в улица на',\n",
       " 'получать2 <dact> глупо']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "rsl_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5336cffa",
   "metadata": {
    "cellId": "7kb5c0waetc47h1fpymd8x"
   },
   "source": [
    "### Preparing data\n",
    "\n",
    "- selecting sentences that have clf in target\n",
    "- saving those input texts and target texts in a separate dataset\n",
    "- droping subjects -> checking number of classifiers\n",
    "- droping objects -> checking number of classifiers\n",
    "\n",
    "If I drop verbs, for sure classifiers will disappear, so it does not make any sense. \n",
    "\n",
    "Then I need to separately drop figures and grounds, but how do I annotate them? I save my separate dataset as csv, then open it in google docs and introduce two new columns figure ground, where I put respective noun phrases. Then I save it as a csv again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18deaa72",
   "metadata": {
    "cellId": "3szukkemjqag9bj37ma9dn"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "for index, row in test_data.iterrows():\n",
    "    if 'clf' not in row['target_text']:  # 112 sentences WITH *clf*\n",
    "        test_data.drop(index, inplace=True)\n",
    "#print(row['target_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "878ecb02",
   "metadata": {
    "cellId": "k0vgn80njyvq4zb9f9i09"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "test_data.drop(['test_stem_rus', 'test_gram_rus', 'test_rsl', 'stem_rus', 'rsl', 'gram_rus'], axis=1, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4856ca49",
   "metadata": {
    "cellId": "zoh2w7ysmrtejppa7xsod7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>а когда дед мороз вернуться домой маленький де...</td>\n",
       "      <td>indx дед.мороз clf clf.группа clf.переместить ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>я весь устраивать я быть интересно учиться и с...</td>\n",
       "      <td>1ps спокойный2 1ps был интересный учиться и вр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>он долго плыть и замечать вдали берег</td>\n",
       "      <td>долго clf clf.плыть clf.на clf.бочка замечать ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>когда мы отжимать волос вода на они оставаться</td>\n",
       "      <td>н-о 1ps жать вода clf clf.вода clf.на clf.воло...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>я тоже хотеть ходить на бал</td>\n",
       "      <td>1ps тоже желание посещать pl clf clf.пышная cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_text  \\\n",
       "0   а когда дед мороз вернуться домой маленький де...   \n",
       "12  я весь устраивать я быть интересно учиться и с...   \n",
       "29              он долго плыть и замечать вдали берег   \n",
       "44     когда мы отжимать волос вода на они оставаться   \n",
       "53                        я тоже хотеть ходить на бал   \n",
       "\n",
       "                                          target_text  \n",
       "0   indx дед.мороз clf clf.группа clf.переместить ...  \n",
       "12  1ps спокойный2 1ps был интересный учиться и вр...  \n",
       "29  долго clf clf.плыть clf.на clf.бочка замечать ...  \n",
       "44  н-о 1ps жать вода clf clf.вода clf.на clf.воло...  \n",
       "53  1ps тоже желание посещать pl clf clf.пышная cl...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b746aeaf",
   "metadata": {
    "cellId": "j1hiswbzppwk5jepc20lr"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "#test_data.to_csv('figure_ground_test_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df5a8236",
   "metadata": {
    "cellId": "5gzqy07mgbgolyfs5uccc8"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "figure_ground_data = pd.read_csv('figure_ground_test_set.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e4e7c4d",
   "metadata": {
    "cellId": "keaol79z7jjq2qaqskx4cl"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>figure</th>\n",
       "      <th>ground</th>\n",
       "      <th>russian_verb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>а когда дед мороз вернуться домой маленький де...</td>\n",
       "      <td>indx дед.мороз clf clf.группа clf.переместить ...</td>\n",
       "      <td>дед мороз, подарок</td>\n",
       "      <td>NaN</td>\n",
       "      <td>вернуться, раздавать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>я весь устраивать я быть интересно учиться и с...</td>\n",
       "      <td>1ps спокойный2 1ps был интересный учиться и вр...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>скоро</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>он долго плыть и замечать вдали берег</td>\n",
       "      <td>долго clf clf.плыть clf.на clf.бочка замечать ...</td>\n",
       "      <td>он</td>\n",
       "      <td>берег</td>\n",
       "      <td>плыть</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>когда мы отжимать волос вода на они оставаться</td>\n",
       "      <td>н-о 1ps жать вода clf clf.вода clf.на clf.воло...</td>\n",
       "      <td>вода</td>\n",
       "      <td>волос</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>я тоже хотеть ходить на бал</td>\n",
       "      <td>1ps тоже желание посещать pl clf clf.пышная cl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>мы знать это животное по мультфильм оно выгляд...</td>\n",
       "      <td>знать вы животное2 мультфильм2 интересный clf ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>мило</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>в год в павловск построить ленинградский восст...</td>\n",
       "      <td>смотреть &lt;nums&gt; год &lt;nums&gt; год павловск &lt;dact&gt;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>построить</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>для кто-то нужно утяжеление для кто-то чтобы б...</td>\n",
       "      <td>&lt;dact&gt; кто тяжелый clf clf.волосы clf.тяжелые ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>утяжеление, разглаживание</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  а когда дед мороз вернуться домой маленький де...   \n",
       "1  я весь устраивать я быть интересно учиться и с...   \n",
       "2              он долго плыть и замечать вдали берег   \n",
       "3     когда мы отжимать волос вода на они оставаться   \n",
       "4                        я тоже хотеть ходить на бал   \n",
       "5  мы знать это животное по мультфильм оно выгляд...   \n",
       "6  в год в павловск построить ленинградский восст...   \n",
       "7  для кто-то нужно утяжеление для кто-то чтобы б...   \n",
       "\n",
       "                                         target_text              figure  \\\n",
       "0  indx дед.мороз clf clf.группа clf.переместить ...  дед мороз, подарок   \n",
       "1  1ps спокойный2 1ps был интересный учиться и вр...                 NaN   \n",
       "2  долго clf clf.плыть clf.на clf.бочка замечать ...                  он   \n",
       "3  н-о 1ps жать вода clf clf.вода clf.на clf.воло...                вода   \n",
       "4  1ps тоже желание посещать pl clf clf.пышная cl...                 NaN   \n",
       "5  знать вы животное2 мультфильм2 интересный clf ...                 NaN   \n",
       "6  смотреть <nums> год <nums> год павловск <dact>...                 NaN   \n",
       "7  <dact> кто тяжелый clf clf.волосы clf.тяжелые ...                 NaN   \n",
       "\n",
       "  ground               russian_verb  \n",
       "0    NaN       вернуться, раздавать  \n",
       "1    NaN                      скоро  \n",
       "2  берег                      плыть  \n",
       "3  волос                        NaN  \n",
       "4    NaN                        NaN  \n",
       "5    NaN                       мило  \n",
       "6    NaN                  построить  \n",
       "7    NaN  утяжеление, разглаживание  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "figure_ground_data.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315e4614",
   "metadata": {
    "cellId": "69bl7m7uzxi6ogry8548qu"
   },
   "source": [
    "I can drop figures\\grounds and in a second experiment drop some other tokens in a sentence (not verb), and compare the effect on final translation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1faec63",
   "metadata": {
    "cellId": "8wyxrrh4aucj9b570ubqlc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "берег\n",
      "волос\n",
      "канализация\n",
      "грудь, стол\n",
      "льдина\n",
      "высокий трава\n",
      "кран\n",
      "берег, вода\n",
      "еда\n",
      "шип\n",
      "пройти\n",
      "плечо\n",
      "вы\n",
      "поезд\n",
      "я\n",
      "капот\n",
      "древолаз\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "import re\n",
    "\n",
    "\n",
    "to_rsl_no_figures = []\n",
    "to_rsl_no_grounds = []\n",
    "\n",
    "for ind, row in  figure_ground_data.iterrows():\n",
    "    \n",
    "    if isinstance(row['figure'], str):\n",
    "        figures = row['figure'].split(', ')\n",
    "        input_text =  row['input_text']\n",
    "        for figure in figures:\n",
    "            input_text = re.sub(figure, '', input_text)\n",
    " \n",
    "        to_rsl_no_figures.append(input_text)\n",
    "    else:\n",
    "        to_rsl_no_figures.append(row['input_text'])\n",
    "    \n",
    "    if isinstance(row['ground'], str):\n",
    "        print(row['ground'])\n",
    "        grounds = row['ground'].split(', ')\n",
    "        input_text_grounds = row['input_text']\n",
    "        for ground in grounds:\n",
    "            input_text_grounds = re.sub(ground, '', input_text_grounds)\n",
    "        \n",
    "        to_rsl_no_grounds.append(input_text_grounds)\n",
    "    else:\n",
    "        to_rsl_no_grounds.append(row['input_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59760f95",
   "metadata": {
    "cellId": "yuhxq57qtinog23ye5a4sq"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "print(len(to_rsl_no_grounds), len(to_rsl_no_figures))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a18b0e",
   "metadata": {
    "cellId": "9zyl8pjnnh7zybrentd5e7"
   },
   "source": [
    "That is a very small amount of data unfortunately, but I cannot take the whole training dataset, becausethe predictions would be unnaturally better, since the model has already seen those sentences.\n",
    "\n",
    "17 with ground, 77 with figure\n",
    "\n",
    "Make the predicitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ed78650",
   "metadata": {
    "cellId": "st4jeuhsjmcq94tqf5vwxe",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195b569c72cd46d3ae5856f6e47691c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3538: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f40573da93e40cdb784353e6f51064d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decoding outputs:   0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "# TODO: Save results to csv and have a look at them\n",
    "rsl_preds_no_figures = model.predict(to_rsl_no_figures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e14e026e",
   "metadata": {
    "cellId": "bxs86x1hkb89wfrb8eqxjj"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c7aa8b066347ce97d19cc138a5756b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfa1aa8986442fc905b78f07e2e52a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decoding outputs:   0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "# TODO: Save results to csv and have a look at them\n",
    "rsl_preds_no_grounds = model.predict(to_rsl_no_grounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43bdde07",
   "metadata": {
    "cellId": "poo62tp9gz3dun665wn6g"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['а когда дед мороз вернуться домой маленький дед мороз приходить к главный и сказать а я то вон в лес тоже подарок раздавать',\n",
       " 'я весь устраивать я быть интересно учиться и скоро я уже сам начало выполнять даже сложный заказ',\n",
       " 'он долго плыть и замечать вдали ',\n",
       " 'когда мы отжимать  вода на они оставаться',\n",
       " 'я тоже хотеть ходить на бал']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "to_rsl_no_grounds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb6f9574",
   "metadata": {
    "cellId": "ahg4oc1nppp58q5x8qge"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['indx дед.мороз маленький домой маленький встретить приходить 1ps дед.',\n",
       " 'все 1ps все устраивать 1ps интересный учиться и скоро выполнять уже готовый',\n",
       " 'плакать clf clf.на clf.бочка замечать видеть',\n",
       " 'н-о 1ps жать вода вода оставаться',\n",
       " '1ps тоже желание ходить 1ps бал']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "rsl_preds_no_grounds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3ebb9a4",
   "metadata": {
    "cellId": "obnhdj4g0v1xetyshsvb6"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "figure_ground_data['rsl_preds_no_grounds'] = rsl_preds_no_grounds\n",
    "figure_ground_data['rsl_preds_no_figures'] = rsl_preds_no_figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbe5b414",
   "metadata": {
    "cellId": "i1x8i3xb9j87tqieypck7a"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "truth_rsl = test_data[\"target_text\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51db26b6",
   "metadata": {
    "cellId": "xhfcs9ut5lakd6iwxc2kf"
   },
   "source": [
    "Count number of classifiers after dropping figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ecb216f",
   "metadata": {
    "cellId": "ik5xw4xkach698xealkpgk"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c2998c6ffc4f61ab5657c0db6b1d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab6029470ca42ce9a378a578803ea65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/98.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c29a894bee14c318bb9ac874948b4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8e3f61c98441608d8bfd65d9cbcbae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "#!g1.1\n",
    "import logging\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"cointegrated/rut5-small\")\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': [\"clf\", \"poss\", \"sg\", \"<nums>\", \"<dact>\", \"1ps\", \"2ps\", \"3ps\", \"indx\", \"pl\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "222e6ae7",
   "metadata": {
    "cellId": "agmyiomxs1dtbhp7jj3id"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def accuracy_by_num_of_clf(truth_rsl, rsl_preds):\n",
    "    test_length = len(truth_rsl)\n",
    "    i = 0\n",
    "    for truth, pred in zip(truth_rsl, rsl_preds):\n",
    "        truth_tokens = [\n",
    "            tokenizer.decode(input_id)\n",
    "            for input_id in tokenizer(truth)['input_ids']\n",
    "        ]\n",
    "        pred_tokens = [\n",
    "            tokenizer.decode(input_id)\n",
    "            for input_id in tokenizer(pred)['input_ids']\n",
    "        ]\n",
    "\n",
    "        truth_clf_n = truth_tokens.count('clf')\n",
    "        pred_clf_n = pred_tokens.count('clf')\n",
    "        if truth_clf_n == pred_clf_n:\n",
    "            i += 1\n",
    "\n",
    "    acc_num = i / test_length\n",
    "    print(round(acc_num*100, 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89596a29",
   "metadata": {
    "cellId": "eea7a0oykbwpcjj20lwv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.179 %\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "accuracy_by_num_of_clf(truth_rsl, rsl_preds_no_grounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edf9d291",
   "metadata": {
    "cellId": "wf3haudcaxii2f25c7oc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.5 %\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "accuracy_by_num_of_clf(truth_rsl, rsl_preds_no_figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc8357d",
   "metadata": {
    "cellId": "ed3w1qz1xxu6e9hohp54c"
   },
   "source": [
    "Now we can drop one token in sentence that has nothing to do with figure\\ground\\verb labels from the data and compare the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5eab16ea",
   "metadata": {
    "cellId": "5n3xzqsj1o718my6nbqzadj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 а\n",
      "9 уже\n",
      "2 замечать\n",
      "5 оставаться\n",
      "2 хотеть\n",
      "10 мы\n",
      "0 в\n",
      "1 кто-то\n",
      "13 поддержка\n",
      "6 чинить\n",
      "2 сидеть\n",
      "5 по\n",
      "0 на\n",
      "7 тяжелый\n",
      "0 этот\n",
      "10 за\n",
      "3 и\n",
      "4 много\n",
      "23 и\n",
      "2 печень\n",
      "6 весь\n",
      "3 сердце\n",
      "7 код\n",
      "9 снижать\n",
      "0 там\n",
      "14 и\n",
      "14 с\n",
      "3 немного\n",
      "9 участвовать\n",
      "6 в\n",
      "7 кто\n",
      "0 а\n",
      "3 красивый\n",
      "1 еще\n",
      "7 пищевой\n",
      "0 если\n",
      "10 бежать\n",
      "3 и\n",
      "1 тема\n",
      "3 куст\n",
      "5 выглядеть\n",
      "13 расщеплять\n",
      "2 и\n",
      "1 расти\n",
      "1 значит\n",
      "1 уничтожать\n",
      "4 папа\n",
      "24 полный\n",
      "12 заалеть\n",
      "9 он\n",
      "1 быть\n",
      "8 то\n",
      "3 не\n",
      "0 называться\n",
      "9 на\n",
      "2 начинать\n",
      "14 растаивать\n",
      "1 ларсить\n",
      "7 защищать\n",
      "0 ладно\n",
      "0 \n",
      "=========\n",
      "10 спать\n",
      "2 окно\n",
      "0 первый\n",
      "1 оборудование\n",
      "3 слабо\n",
      "0 попадать\n",
      "6 комната\n",
      "0 \n",
      "=========\n",
      "14 выделять\n",
      "4 нужно\n",
      "5 весь\n",
      "11 они\n",
      "5 в\n",
      "11 ткань\n",
      "2 платить\n",
      "2 бальзам\n",
      "11 психосоматический\n",
      "0 на\n",
      "3 один\n",
      "3 давать\n",
      "3 начало\n",
      "3 максимальный\n",
      "5 знать\n",
      "6 шаг\n",
      "0 мочь\n",
      "0 \n",
      "=========\n",
      "4 трехэтажный\n",
      "0 к\n",
      "1 это\n",
      "1 после\n",
      "11 место\n",
      "7 день\n",
      "8 характер\n",
      "7 на\n",
      "0 похоже\n",
      "14 то\n",
      "3 снова\n",
      "8 в\n",
      "11 самый\n",
      "8 и\n",
      "3 тот\n",
      "5 и\n",
      "5 погодный\n",
      "3 человек\n",
      "7 друг\n",
      "2 замечать\n",
      "4 пятно\n",
      "0 она\n",
      "13 представление\n",
      "1 дорогой\n",
      "5 в\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "import random\n",
    "\n",
    "\n",
    "to_rsl_random_remove = []\n",
    "\n",
    "for ind, row in  figure_ground_data.iterrows():\n",
    "    \n",
    "    marked_entities = []\n",
    "    \n",
    "    if isinstance(row['figure'], str):\n",
    "        figures = row['figure'].split(', ')\n",
    "        marked_entities.extend(figures)\n",
    "    if isinstance(row['ground'], str):\n",
    "        grounds = row['ground'].split(', ')\n",
    "        marked_entities.extend(grounds)\n",
    "    if isinstance(row['russian_verb'], str):\n",
    "        verbs = row['russian_verb'].split(', ')\n",
    "        marked_entities.extend(verbs)\n",
    "    \n",
    "    input_plain = row['input_text']\n",
    "    for word in marked_entities:\n",
    "        input_plain = re.sub(word, '', input_plain)\n",
    "       \n",
    "    if ' ' in input_plain:\n",
    "        input_tokens = input_plain.split()\n",
    "    else:\n",
    "        input_tokens = [input_plain]\n",
    "    sent_len = len(input_tokens)\n",
    "    #print(sent_len, input_tokens)\n",
    "    index = random.randint(0, sent_len-1)\n",
    "    random_word_remove = input_tokens[index]\n",
    "    print(index, random_word_remove)\n",
    "    \n",
    "    input_plain_two = row['input_text']\n",
    "    if random_word_remove != '':\n",
    "        to_rsl = re.sub(random_word_remove, '', input_plain_two)\n",
    "        to_rsl_random_remove.append(to_rsl)\n",
    "    else: \n",
    "        print('=========')\n",
    "        to_rsl_random_remove.append(row['input_text'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60180c23",
   "metadata": {
    "cellId": "edpkg0eonm4mbt8pq6o7cn",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['а когда дед мороз вернуться  маленький дед мороз приходить к главный и сказать а я то вон в лес тоже подарок раздавать',\n",
       " 'я  устраивать я быть интересно учиться и скоро я уже сам начало выполнять даже сложный заказ',\n",
       " 'он долго плыть и  вдали берег',\n",
       " 'когда мы отжимать волос вода на  оставаться',\n",
       " 'я  хотеть ходить на бал',\n",
       " 'мы знать это животное по  оно выглядеть так мило что мы и не думать о то что оно опасный а оно опасный',\n",
       " 'в  в павловск построить ленинградский восстановительный центр',\n",
       " 'для  нужно утяжеление для  чтобы быть разглаживание',\n",
       " 'я обращаться и в другой место например в вога и там я тоже оформлять письмо поддержка такой образ уже они у я  несколько',\n",
       " 'а этот мужчна быть сантехнк который чнть прорыв каналзаця  который облвать дерьмо тома давать он халат муж  разрешать подождать пока он првозть чстый вещь',\n",
       " 'пока спасатель ехать мальчк сдеть рядом  следть',\n",
       " 'он мочь бить себя по грудь или по стол пытаться  что он плохо и нужный помощь',\n",
       " 'медвежонок плыть  льди',\n",
       " 'например дма  заставлять  делать самый тяжелый работая',\n",
       " 'этот верхний пункт сокращать но затратный ресурс быть ',\n",
       " 'он приносить одеяло из дом и накрывать собака обращаться к  за помощь',\n",
       " 'вдмо становться больше сажать культура  з-за большой колчество урожай он становться собраться поздно',\n",
       " 'в это место очень много турист благодаря то что  много исторический здание',\n",
       " 'потому что нет общение нет любовь и понимние и он быть просто кк собчк это очень стршно  у тот трое быть семья любовь общение и вот это рельно до муршки',\n",
       " ' с печень желчный пузырь который удерживать желчь до необходимый момент',\n",
       " 'дотащить он мешок в  и раздавать подарок весь животное они очень обрадоваться',\n",
       " 'он лежать мертый  ысокий траа и  сердце у он быть острый шип',\n",
       " 'например здесь в россия мы открывать свой организация код но мы выбирать русскоязычный название  ребенок в семья глухой',\n",
       " 'и улучшать углеводный обмен а именно  рецептор клетка инсулин они снижать аппетит и тяга к сладкий поэтому вечерний капсула рекомендоваться принимать за минута до еда',\n",
       " 'там уже быть показываться  новость',\n",
       " 'быть момент когда  нужно быть находить музей и  обращатьс к наставник а они находить нужный человек и обменть мы номер',\n",
       " 'а кролик сидеть в мешок переживать вспоминать хороший время  играть с мальчик и общаться с лощадь',\n",
       " ' год есь немного поутихнуть и решать проодить II съезд глухой',\n",
       " 'там рассматривать мой проект  чем помогать и помогать я стараться участвовать в любой соревнование в новосибирск и другой город буквально в любой',\n",
       " 'когда льдина уже почти  он увидеть в вода деревянный бочка',\n",
       " 'поэтому должный быть отдельный  для тот кто хотеть продолжать качественно учиться с переводчик',\n",
       " 'а за  деньги куда пойти',\n",
       " ' посмотреть вверх и увидеть красивый голубой небо и облако',\n",
       " 'можно еще кондиционер в вид пена он  сглаживать волос и придавать  увлажнение',\n",
       " 'двигаться в правильный направление в пищевод это называться пищевой ',\n",
       " 'если  невозможно у вы быть пара минута чтобы добегать до туалет и расслабляться',\n",
       " 'так плохой труба и канализация где протекать плохой вода и из кран так  бежать плохой и ржавый вода',\n",
       " 'они часто приходить на берег и  прыгать в вода',\n",
       " 'переходить к ',\n",
       " 'и на розовый  на самый верхний побег начало распускаться великолепный роза',\n",
       " 'главное смотреть на то как  волос и что вы нужно на каждый день',\n",
       " 'пр пережевыване еда распадаться на кусочек чтобы органзм быть легко нужный слюна она смешваться с еда  расщеплять она',\n",
       " 'весь крепко и крепко прижиматься соловей к шип и песня он звучать весь громко и громко  он петь о зарождение страсть в душа мужчина и девушка',\n",
       " 'лето  вкусный яблоко',\n",
       " 'вот значит ствол дерево это возникать проблема нужно  каков е причина и какой оказываться последствие',\n",
       " 'они уничтожать танк противник с то  обеспечивать дальнейший продвижение пехота',\n",
       " 'м мама  м папа закаляться не знать каждый день чтобы не заболевать обливаться хлодный вода ну знать стоять под холодный душ',\n",
       " 'если не получаться то во время реанимация инородный тело оно пройти в один из бронх и тогда один из легкий смочь дышать дыхание будет  не в полный объем',\n",
       " 'крепко  ко я милый соловушка не то день прийти рано чем заалеть роза',\n",
       " 'и вот мы сыграть свадьба и я  к он у они быть три комната в квартира',\n",
       " 'обязательно быть ошибка а расчет ',\n",
       " 'есл у вы волос торчать то  вы хотеть он сглажвать то нужно спользовать коллаген шелк кератн  белок',\n",
       " 'чуть в легкий не ',\n",
       " 'сжимание стенка называться ',\n",
       " 'а проблема то в то что мы мочь говорить на жестовый один рука а в англия человек так  мочь',\n",
       " 'первый  укусить начинать жевать',\n",
       " 'температура то повышаться то понжаться снег мочь то неделя лежать а мочь мало  потом раставать',\n",
       " 'медвежонок ларсить жить на  полюс вместе с мама и папа',\n",
       " 'весь спрашивать  на юг так популярный одежда защищать от ветер',\n",
       " ' сам доносить',\n",
       " 'гаснуть',\n",
       " 'эхо понести этот  к свой багряный пещера в гора и разбудить спать там пастух',\n",
       " ' он высовываться з окно  сорвать она',\n",
       " 'первый это хлопок по ',\n",
       " ' привозить оборудование который предоставлять электричество',\n",
       " 'получаться столбец не  слабо  средне  сильно ',\n",
       " '',\n",
       " 'и он вернуться к себя в комната вытаскивать большой запылить книга и  она читать',\n",
       " 'подымать',\n",
       " 'у третьяков быть хобб он быть меценат  оплачвать стротельство школа для глухой ребенок выделять целый тысяча на это  в год построть трехэтажный здане школа',\n",
       " 'смотреть  он обучать что нужно добавлять',\n",
       " 'когда у маленький дед мороз весь подарок быть готовый остальной вс думать  снова надо будет ехать дарить ребенок подарок возвращаться домой  это очень скучно',\n",
       " 'семен по путь с работа забирать дочка из садик и к ужин они сегда быть дом но не  этот злосчастный день',\n",
       " 'и по  начинать собирать человек на съезд в москва начинаться беготня в общий постанавливать собирать человек в москва в июль год',\n",
       " 'благодаря плодоножка вишня в организм не накапливаться лишний жидкость а в жировой ткань активизироваться  микроциркуляция',\n",
       " 'спонсор  платить я выполнять проект в это город нехватать мыло я сообщать спонсор получать мыло и раздавать',\n",
       " 'важный  бальзам если волос повреждать и торчать',\n",
       " ' к вы приш л пациент со свой проблема и вы выяснять что у он быть психосоматический влияние',\n",
       " 'выделять деньги  школа',\n",
       " 'мужчи схватывать чемодан в один рука сумка в другой и  ход потому что поезд уже чить медленно ехать вскакивать  ступенька',\n",
       " 'деньги я не давать но выписывать  письмо письмо поддержка начальство поставлять печать',\n",
       " 'в конец июнь начало июль уже созревать вишня черешня ',\n",
       " ' помогать запускать обмен вещество на максимальный скорость работа щитовидный железа давать прилив энергия и хороший настроение а вечер наоборот успокаивать настраивать на хороший сон и защищать от обжорство и ускорять расход жир из наш запас',\n",
       " 'потом я  свой ребенок который знать жестовый язык он весело подходить ко я',\n",
       " ' капсула пролонгировать лимфодренажный эффект получать на первый шаг',\n",
       " 'мочь быть  смочь взламывать сенсор ааа он на работа',\n",
       " 'узкий',\n",
       " 'так вот  построить трехэтажный здание школа а рядом еще больница построить',\n",
       " 'к пример я экскурсовод  не приходить человек так называть экскурсант',\n",
       " ' это огромный количество энергия который обрушиваться на мы и мы не знать куда он потратить',\n",
       " 'утро принимать два капсула после еда вечер  минута до ужин',\n",
       " 'они бродить до утро по улица а потом поехать на вокзал и снова они место  рядом',\n",
       " 'саша сломать нога из-за это сегодня не прийти на день ',\n",
       " 'весь человек разный у весь разный работа  характер разный то что я объяснять это не готовый формула успех главное я давать вы правльный направлене',\n",
       " ' быть такой автомобиль красивый длинный с олень на капот',\n",
       " ' откусывать сэндвич',\n",
       " 'и вот изображение стекло запотевать он начинать он протирать и когда протирать начинать проявляться картина то  он хотеть',\n",
       " 'если не помогать  производить хлопок пока ни получаться',\n",
       " 'получаться при минимальный увеличение  обмен вещество в организм замедляться в раз',\n",
       " 'древолаз очень токсичный и бывать разный цветок желтый темно-зеленый красный черный но самый опасный ',\n",
       " 'веко защекотать слезинка когда поезд тронуться но вдруг дверь в  открываться и входить роберт',\n",
       " 'а куст кричать соловей чтобы тот еще  прижиматься к шип',\n",
       " 'из жир так же как и из белок строиться клетка оболочка мембрана без жир не образовываться поэтому часть жир идти на строительство этот мембрана и не  мы энергия',\n",
       " 'быать что  сязь с погодный услоие обледенеать и обораться проод но опять же такой случаться редко',\n",
       " 'мы  что человек стоять взгляд испуганный',\n",
       " 'код из разный страна сразу  друг друг радоваться начинать взаимодействовать друг с другой',\n",
       " 'вдруг  замечать вдалеке свой папа',\n",
       " ' рыба фуга большой круглый рыба с пятно',\n",
       " 'на вхдить вытирать рука  плтенце',\n",
       " 'следующий лебедь очень красивый птица который  пара и с который у мы связанный много представление о любовь',\n",
       " ' дорогой цена за красный роза восклицать соловей',\n",
       " 'отражение роза в серебряный зеркало отражение роза в недвижный вода вот каков быть роза расцветать на верхний  куст']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "to_rsl_random_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d669cad7",
   "metadata": {
    "cellId": "kgaez7onyxl91yv5o1orf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 112\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "print(len(truth_rsl), len(to_rsl_random_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6adaca26",
   "metadata": {
    "cellId": "5mpzhm0tx5i0tqcbj3jrq0o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 %\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "accuracy_by_num_of_clf(truth_rsl, to_rsl_random_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c50155",
   "metadata": {
    "cellId": "j84of29lcvb0zkz4czkn6q"
   },
   "source": [
    "Why this score is so low if are careful about not dropping parts of a classifier? Maybe because we did drop mostly verbs any way, and we should cut out verbs too"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "3b394e2e-1922-46d5-bf21-3ea87184a3a6",
  "notebookPath": "Notebooks/removing_tokens.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
